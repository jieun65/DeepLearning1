{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Google Colab í™˜ê²½ì—ì„œ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
        "Korean Hate Speech Detectionì˜ ì…ë ¥ í…ìŠ¤íŠ¸ì—ì„œ ê°ì • ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•˜ì—¬ Sentiment Analysisì—ì„œ í•™ìŠµ(fine-tuning)í•œ ëª¨ë¸ì„ í™œìš©í•˜ì˜€ìŠµë‹ˆë‹¤.  \n",
        "ë”°ë¼ì„œ Sentiment Analysisë¥¼ ì§„í–‰í•œ ì´í›„ì— Korean Hate Speech Detectionì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.  \n",
        "ë“œë¼ì´ë¸Œì— ë§ˆìš´íŠ¸í•˜ëŠ” ì½”ë“œì™€ ë°ì´í„°ì…‹ì„ ê°€ì ¸ì˜¤ëŠ” ì½”ë“œì—ì„œëŠ” **ë°ì´í„°ì…‹ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì§€ì •**í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.  \n",
        "ë˜í•œ ëª¨ë¸ì´ ì¶”ë¡ (inference)ì„ ìˆ˜í–‰í•˜ëŠ” ì½”ë“œì—ì„œëŠ” **ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³ ì í•˜ëŠ” ëª¨ë¸ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì§€ì •**í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.  \n",
        "Sentiment Analysisì˜ Model Training ì½”ë“œì—ì„œëŠ” early stopping ìˆ˜í–‰ ì—¬ë¶€ì— ë”°ë¼ **ë‘ ë¸”ë¡ì˜ í•™ìŠµ ì½”ë“œ ì¤‘ í•˜ë‚˜ë§Œ ì‹¤í–‰**í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n"
      ],
      "metadata": {
        "id": "kxf_XUrnBlwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment settings"
      ],
      "metadata": {
        "id": "zl0HOW1cLDzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### install modules"
      ],
      "metadata": {
        "id": "gIwJ776uxPaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# í…ìŠ¤íŠ¸ ì´ëª¨ì§€ ì „ì²˜ë¦¬\n",
        "!pip install --quiet emoji==2.11.1"
      ],
      "metadata": {
        "id": "cB9N7Xc-vb0V"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import modules"
      ],
      "metadata": {
        "id": "XbxHKYMJQv7K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "cvptqBeLMmXU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os                               # file systemì— ì ‘ê·¼\n",
        "import re, html, unicodedata, emoji     # text preprocessingì˜ regular expression\n",
        "import gc                               # GPU memory cache ì²­ì†Œ\n",
        "import time\n",
        "\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
        "from transformers.optimization import get_scheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
        "from tqdm import tqdm                   # model training/validation/testì—ì„œ í•™ìŠµ ê³¼ì •ì„ ì‹œê°í™”\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### drive mount"
      ],
      "metadata": {
        "id": "dbGjp7UrRFvK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOvCBqjpPJjm",
        "outputId": "fb519075-ccb1-407c-9362-8269e1c08705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "kmN7KUvGMz65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "304dcc61-a816-4d1b-bbd7-62dc64c19b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DeepLearning/sentiment.csv\n",
            "/content/drive/MyDrive/DeepLearning/test.tsv\n",
            "/content/drive/MyDrive/DeepLearning/validation.tsv\n",
            "/content/drive/MyDrive/DeepLearning/train.tsv\n",
            "/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152/model/config.json\n",
            "/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152/model/model.safetensors\n",
            "/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152/tokenizer/tokenizer_78b3253a26.model\n",
            "/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152/tokenizer/tokenizer_config.json\n",
            "/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152/tokenizer/vocab.txt\n",
            "/content/drive/MyDrive/DeepLearning/hate_speech/UICHEOL-HWANG_kobert_20250621-155603/model/pytorch_model.bin\n",
            "/content/drive/MyDrive/DeepLearning/hate_speech/UICHEOL-HWANG_kobert_20250621-155603/tokenizer/tokenizer_78b3253a26.model\n",
            "/content/drive/MyDrive/DeepLearning/hate_speech/UICHEOL-HWANG_kobert_20250621-155603/tokenizer/vocab.txt\n",
            "/content/drive/MyDrive/DeepLearning/hate_speech/UICHEOL-HWANG_kobert_20250621-155603/tokenizer/tokenizer_config.json\n"
          ]
        }
      ],
      "source": [
        "# directory check\n",
        "DIRECTORY = \"/content/drive/MyDrive/DeepLearning/\"\n",
        "for dirname, _, filenames in os.walk(DIRECTORY):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cuda"
      ],
      "metadata": {
        "id": "sBUqApGJRaL_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "oRHvi6v0Ob9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4fb897-b79b-477f-eb01-0633c7dce555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í˜„ì¬ device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# ëŸ°íƒ€ì„ - ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ - T4 GPU ì„ íƒ - ì €ì¥(ì €ì¥ í•„ìˆ˜)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"í˜„ì¬ device: {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(f\"í˜„ì¬ device: {device}\")\n",
        "    print(\"GPU ì•ˆ ì“°ë©´ í•™ìŠµ ëª»í•¨(ì§„ì§œì„)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline: Sentiment Analysis"
      ],
      "metadata": {
        "id": "d7iiafktAc-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label dictionary\n",
        "LABEL_2_ID = {\n",
        "    \"ê³µí¬\": 0,\n",
        "    \"ë†€ëŒ\": 1,\n",
        "    \"ë¶„ë…¸\": 2,\n",
        "    \"ìŠ¬í””\": 3,\n",
        "    \"ì¤‘ë¦½\": 4,\n",
        "    \"í–‰ë³µ\": 5,\n",
        "    \"í˜ì˜¤\": 6,\n",
        "}\n",
        "ID_2_LABEL = {value: key for key, value in LABEL_2_ID.items()}"
      ],
      "metadata": {
        "id": "ZLk4dgXAPMSR"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "iEae5UWya5lQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(os.path.join(DIRECTORY, 'sentiment.csv'))"
      ],
      "metadata": {
        "id": "zOZCCrF-Nnb3"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "id": "vIXLnkkXNt2s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "39fa3f41-485d-4e8f-8a50-852f50bea5d3",
        "collapsed": true
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                Sentence Emotion\n",
              "0                               ì–¸ë‹ˆ ë™ìƒìœ¼ë¡œ ë¶€ë¥´ëŠ”ê²Œ ë§ëŠ” ì¼ì¸ê°€ìš”..??      ê³µí¬\n",
              "1                                           ê·¸ëƒ¥ ë‚´ ëŠë‚Œì¼ë¿ê² ì§€?      ê³µí¬\n",
              "2                                         ì•„ì§ë„ˆë¬´ì´ˆê¸°ë¼ì„œ ê·¸ëŸ°ê±°ì£ ?      ê³µí¬\n",
              "3                                          ìœ ì¹˜ì›ë²„ìŠ¤ ì‚¬ê³  ë‚«ë‹¤ë˜ë°      ê³µí¬\n",
              "4                                            ê·¼ë° ì›ë˜ì´ëŸ°ê±°ë§ë‚˜ìš”      ê³µí¬\n",
              "...                                                  ...     ...\n",
              "38589               ì†”ì§íˆ ì˜ˆë³´ ì œëŒ€ë¡œ ëª»í•˜ëŠ” ë° ì„¸ê¸ˆì´ë¼ë„ ì•„ë¼ê²Œ ê·¸ëƒ¥ íì§€í•´ë¼..      í˜ì˜¤\n",
              "38590                                        ì¬ë¯¸ê°€ ì—†ìœ¼ë‹ˆ ë§í•˜ì§€      í˜ì˜¤\n",
              "38591  ê³µì¥ ë„ì‹œë½ ë¹„ìš°ìƒì ì„ ì•„ë¥´ë°”ì´íŠ¸í–ˆëŠ”ë° í™”ì¥ì‹¤ê°€ì„± ì†ë„ ì•Šì”¯ê³  ì¬ë£Œ ë‹´ê³  ë°”ë‹¥ ë–¨ì–´...      í˜ì˜¤\n",
              "38592               ì½”ë”±ì§€ ë§Œí•œ ë‚˜ë¼ì—ì„œ ì§€ë“¤ë¼ë¦¬ í”¼í„°ì§€ê²Œ ì‹¸ìš°ëŠ” ì„¼ì§• í´ë˜ìŠ¤ ã…‰ã…‰ã…‰      í˜ì˜¤\n",
              "38593               ì™€ì´í”„ë„ ê·¸ë ‡ê³  ëŒ“ê¸€ ë‹¤ ë³¼í…ë° ì´íœ˜ì¬ ì¢€ í•˜ì°¨ í•˜ë¼ê³  ì „í•´ì£¼ì„¸ìš”      í˜ì˜¤\n",
              "\n",
              "[38594 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-676cdc16-45f0-4932-92e8-d743f75208f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ì–¸ë‹ˆ ë™ìƒìœ¼ë¡œ ë¶€ë¥´ëŠ”ê²Œ ë§ëŠ” ì¼ì¸ê°€ìš”..??</td>\n",
              "      <td>ê³µí¬</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ê·¸ëƒ¥ ë‚´ ëŠë‚Œì¼ë¿ê² ì§€?</td>\n",
              "      <td>ê³µí¬</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ì•„ì§ë„ˆë¬´ì´ˆê¸°ë¼ì„œ ê·¸ëŸ°ê±°ì£ ?</td>\n",
              "      <td>ê³µí¬</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ìœ ì¹˜ì›ë²„ìŠ¤ ì‚¬ê³  ë‚«ë‹¤ë˜ë°</td>\n",
              "      <td>ê³µí¬</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ê·¼ë° ì›ë˜ì´ëŸ°ê±°ë§ë‚˜ìš”</td>\n",
              "      <td>ê³µí¬</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38589</th>\n",
              "      <td>ì†”ì§íˆ ì˜ˆë³´ ì œëŒ€ë¡œ ëª»í•˜ëŠ” ë° ì„¸ê¸ˆì´ë¼ë„ ì•„ë¼ê²Œ ê·¸ëƒ¥ íì§€í•´ë¼..</td>\n",
              "      <td>í˜ì˜¤</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38590</th>\n",
              "      <td>ì¬ë¯¸ê°€ ì—†ìœ¼ë‹ˆ ë§í•˜ì§€</td>\n",
              "      <td>í˜ì˜¤</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38591</th>\n",
              "      <td>ê³µì¥ ë„ì‹œë½ ë¹„ìš°ìƒì ì„ ì•„ë¥´ë°”ì´íŠ¸í–ˆëŠ”ë° í™”ì¥ì‹¤ê°€ì„± ì†ë„ ì•Šì”¯ê³  ì¬ë£Œ ë‹´ê³  ë°”ë‹¥ ë–¨ì–´...</td>\n",
              "      <td>í˜ì˜¤</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38592</th>\n",
              "      <td>ì½”ë”±ì§€ ë§Œí•œ ë‚˜ë¼ì—ì„œ ì§€ë“¤ë¼ë¦¬ í”¼í„°ì§€ê²Œ ì‹¸ìš°ëŠ” ì„¼ì§• í´ë˜ìŠ¤ ã…‰ã…‰ã…‰</td>\n",
              "      <td>í˜ì˜¤</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38593</th>\n",
              "      <td>ì™€ì´í”„ë„ ê·¸ë ‡ê³  ëŒ“ê¸€ ë‹¤ ë³¼í…ë° ì´íœ˜ì¬ ì¢€ í•˜ì°¨ í•˜ë¼ê³  ì „í•´ì£¼ì„¸ìš”</td>\n",
              "      <td>í˜ì˜¤</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38594 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-676cdc16-45f0-4932-92e8-d743f75208f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-676cdc16-45f0-4932-92e8-d743f75208f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-676cdc16-45f0-4932-92e8-d743f75208f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d6dc0e78-6adc-479d-9c7f-7b8363f9a1d8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6dc0e78-6adc-479d-9c7f-7b8363f9a1d8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d6dc0e78-6adc-479d-9c7f-7b8363f9a1d8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_042dbba5-c948-4910-8f83-0b4935a60e4c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_042dbba5-c948-4910-8f83-0b4935a60e4c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 38594,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38509,\n        \"samples\": [\n          \"\\uac00\\uc815\\uc6a9\\ub204\\uc9c4\\uc138\\ub85c \\ubb50\\ud574\\uccd0\\uba39\\uc744\\ub7ec\\uace0 \\uc804\\uae30\\ub8cc \\ube44\\uc2f8\\uac8c\\ubc1b\\uc544\\uba39\\uace0 \\ub204\\uc9c4\\uc138 \\ud3d0\\uc9c0\\ud558\\uba74 \\ub420\\uac83\\uc744 \\uc800\\ub807\\uac8c \\uc2f8\\uc6b0\\uace0\\uc788\\uace0\",\n          \" \\uc544\\ub2c8\\uba74 \\uc11c\\ub85c \\ub9de\\uc9c0 \\uc54a\\uc544\\uc11c \\uadf8\\ub7f0\\uac78\\uae4c\\uc694?\",\n          \" \\uba54\\ub974\\ub610- \\uac70\\ub9ac\\ub294\\ub370 \\uc5b4\\uca4c\\uba74 \\uc88b\\uc8e0\\ub3cc\\uc544\\ubc84\\ub9b4\\uac83 \\uac19\\uc74c0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"\\uacf5\\ud3ec\",\n          \"\\ub180\\ub78c\",\n          \"\\ud589\\ubcf5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "RT3tcXtGO0fo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checking missing data"
      ],
      "metadata": {
        "id": "kNP5tkdRR18A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking missing data\n",
        "mask = (df[\"Sentence\"].fillna('').str.len() == 0) | (~df[\"Emotion\"].isin(LABEL_2_ID))\n",
        "if mask.any(): print(f\"{mask.sum()} missing datas\")\n",
        "else: print(\"no missing data\")"
      ],
      "metadata": {
        "id": "S7CkfILGOyTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea2f9818-ea3c-4e09-e246-158072d2c7c4"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no missing data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### outliar processing"
      ],
      "metadata": {
        "id": "-jdd-XqQR8e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL_PAT = re.compile(r'https?://\\S+')\n",
        "HTML_PAT = re.compile(r'<[^>]+>')\n",
        "REPEAT_PAT = re.compile(r'(.)\\1{2,}')                       # 3íšŒ ì´ìƒ ì—°ì†ëœ ê¸€ì(ã…‹ã…‹ã…‹, ã… ã… ã…  ë“±) â†’ 2íšŒë¡œ ì¶•ì•½\n",
        "SPEC_PAT = re.compile(r'[^ã„±-ã…ê°€-í£a-zA-Z0-9\\s\\.\\,\\!\\?]+') # í—ˆìš© ë¬¸ì: í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±, ì£¼ìš” punctuation\n",
        "MULTI_SP = re.compile(r'\\s+')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = html.unescape(text)                          # &quot; â†’ \"\n",
        "    text = URL_PAT.sub(' URL ', text)                   # URL í† í°í™”\n",
        "    text = HTML_PAT.sub(' ', text)                      # HTML tag ì œê±°\n",
        "    text = emoji.demojize(text, delimiters=(' ', ' '))  # ğŸ˜€ â†’ :grinning_face:\n",
        "    text = REPEAT_PAT.sub(r'\\1\\1', text)                # ã…‹ã…‹ã…‹ã…‹ â†’ ã…‹ã…‹\n",
        "    text = SPEC_PAT.sub(' ', text)                      # íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
        "    text = unicodedata.normalize('NFKC', text)          # Unicode ì •ê·œí™”\n",
        "    text = MULTI_SP.sub(' ', text).strip()              # ë‹¤ì¤‘ ê³µë°± ì •ê·œí™”\n",
        "    return text\n",
        "\n",
        "df[\"Sentence\"] = df[\"Sentence\"].apply(clean_text)"
      ],
      "metadata": {
        "id": "VsvvuRwvPzgX"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset balancing"
      ],
      "metadata": {
        "id": "s-6AEU1FSp6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = (\n",
        "    df.groupby(\"Emotion\")\n",
        "    .apply(lambda x: x.sample(n=df[\"Emotion\"].value_counts().min(), random_state=42))   # down-sampling\n",
        "    .reset_index(drop=True)                                                             # multi-index ë°©ì§€\n",
        "    .sample(frac=1, random_state=42)\n",
        "    .reset_index(drop=True)\n",
        ")"
      ],
      "metadata": {
        "id": "7qFKt6sKSqTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d2c8ef-450c-4b92-a9a2-dc20f6d619b3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-69-349119925.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda x: x.sample(n=df[\"Emotion\"].value_counts().min(), random_state=42))   # down-sampling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### target digitize"
      ],
      "metadata": {
        "id": "c0OP6H_dSKrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [\"ê³µí¬\", \"ë†€ëŒ\", \"ë¶„ë…¸\", ...] => [0, 1, 2, ...]\n",
        "df[\"Emotion\"] = df[\"Emotion\"].replace(LABEL_2_ID)"
      ],
      "metadata": {
        "id": "D6zINkDQSKzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e030355-02fe-4c37-a2df-08f09817c585"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-70-3228976304.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"Emotion\"] = df[\"Emotion\"].replace(LABEL_2_ID)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset slicing"
      ],
      "metadata": {
        "id": "ql00GoPtVkX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# colabì˜ GPU ë©”ëª¨ë¦¬/ì—°ì‚° í• ë‹¹ëŸ‰ ì œí•œìœ¼ë¡œ ì¸í•´ datasetì˜ ì¼ë¶€ë§Œ í•™ìŠµì— ì‚¬ìš©\n",
        "df = df.iloc[:30000]"
      ],
      "metadata": {
        "id": "DwikQ4TCVjs3"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "collapsed": true,
        "id": "nYspxI3Pln0m",
        "outputId": "e28cb808-def6-4996-affc-9571fc5cc897"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                             Sentence  Emotion\n",
              "0                    ì´ê±´ ì˜í•˜ëŠ”ê²ƒ ê°™ì€ë° ë§ì´ë‹¤.        0\n",
              "1                     ê·¸ì¹˜ë§Œ íƒ€ì´ë°ì´ ë¬¸ì œë„¤ìš”..        0\n",
              "2                                ëŒ€ë°•??        5\n",
              "3                  ì‹œê¸‰ 1600ì› ë¡œë´‡ ì‹œê¸‰ì´ í—?        1\n",
              "4                          ì˜¤ëŠ˜ ì§€ì§„ ëŒ€ë°•ì´ë‹¤        1\n",
              "...                               ...      ...\n",
              "29995                  ì§„ì§œ ë„¤ì´íŠ¸ì˜¨ë§Œí•´ì•¼í•´?á„á„        0\n",
              "29996                  ë­˜í•´ë„ ì§‘ì¤‘ì´ì•ˆë¼..í˜ë“¤ì–´        0\n",
              "29997  ì˜¬í•´ í•œêµ­ì‹œë¦¬ì¦ˆëŠ” ìµœìˆœì‹¤ì´í•œí…Œ ë¬»í˜€ì„œ ì¡°ìš©íˆ ëë‚¬ë„¤..        6\n",
              "29998        ë•ë¶„ì— ìƒˆëŒì´ í—¤ë§¤ì§€ ì•Šì„ ìˆ˜ ìˆê²Œ ë˜ì—ˆì–´ìš”        5\n",
              "29999         ì•Œë°”í•˜ë©´ì„œ ì·¨ì—… ì¤€ë¹„ ì˜ í•  ìˆ˜ ìˆì„ê¹Œìš”?        0\n",
              "\n",
              "[30000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ec2418d-73a0-47d2-bfd9-784eea3d9e49\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ì´ê±´ ì˜í•˜ëŠ”ê²ƒ ê°™ì€ë° ë§ì´ë‹¤.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ê·¸ì¹˜ë§Œ íƒ€ì´ë°ì´ ë¬¸ì œë„¤ìš”..</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ëŒ€ë°•??</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ì‹œê¸‰ 1600ì› ë¡œë´‡ ì‹œê¸‰ì´ í—?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ì˜¤ëŠ˜ ì§€ì§„ ëŒ€ë°•ì´ë‹¤</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>ì§„ì§œ ë„¤ì´íŠ¸ì˜¨ë§Œí•´ì•¼í•´?á„á„</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>ë­˜í•´ë„ ì§‘ì¤‘ì´ì•ˆë¼..í˜ë“¤ì–´</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>ì˜¬í•´ í•œêµ­ì‹œë¦¬ì¦ˆëŠ” ìµœìˆœì‹¤ì´í•œí…Œ ë¬»í˜€ì„œ ì¡°ìš©íˆ ëë‚¬ë„¤..</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>ë•ë¶„ì— ìƒˆëŒì´ í—¤ë§¤ì§€ ì•Šì„ ìˆ˜ ìˆê²Œ ë˜ì—ˆì–´ìš”</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>ì•Œë°”í•˜ë©´ì„œ ì·¨ì—… ì¤€ë¹„ ì˜ í•  ìˆ˜ ìˆì„ê¹Œìš”?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ec2418d-73a0-47d2-bfd9-784eea3d9e49')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ec2418d-73a0-47d2-bfd9-784eea3d9e49 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ec2418d-73a0-47d2-bfd9-784eea3d9e49');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-03b4820b-05c8-4263-b6bf-264cb10c7f5a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03b4820b-05c8-4263-b6bf-264cb10c7f5a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-03b4820b-05c8-4263-b6bf-264cb10c7f5a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7698e826-3f6c-4ec4-b953-4d52845b0668\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7698e826-3f6c-4ec4-b953-4d52845b0668 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30000,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29902,\n        \"samples\": [\n          \"\\uc8fd\\uc744\\uac83 \\uac19\\ub2e4\",\n          \"\\uc11c\\uc7a5\\ud6c8 \\ub3c4\\ub300\\uccb4 \\uc774\\uac8c \\ubb34\\uc2a8 \\uc758\\ubbf8\\uac00 \\uc788\\uc2b5\\ub2c8\\uae4c\",\n          \"\\uc131\\uc870\\uae30\\ub294 \\uc65c \\ud754\\ub4e4\\uace0 \\ub09c\\ub9ac\\uc57c!!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Emotion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset split"
      ],
      "metadata": {
        "id": "mxwCMCu1WqZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# featureì™€ target ë¶„ë¦¬\n",
        "texts = df[\"Sentence\"].tolist()\n",
        "labels = df[\"Emotion\"].tolist()\n",
        "\n",
        "# train/validation/test split\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    texts, labels,\n",
        "    test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_texts, train_labels,\n",
        "    test_size=0.25, random_state=42, stratify=train_labels\n",
        ")"
      ],
      "metadata": {
        "id": "OQif8Yq4WplB"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Tokenize"
      ],
      "metadata": {
        "id": "RgDC4yOKXgcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"UICHEOL-HWANG/kobert\"\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "Fi7medmLw2rw"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Tokenize"
      ],
      "metadata": {
        "id": "1l2QlNbkw2z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    ë¬¸ì¥ê³¼ ë¼ë²¨ì„ ì½ì–´\n",
        "    Transformer í† í¬ë‚˜ì´ì €ë¡œ encoding\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=64):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.texts[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "# Datasetì˜ ì—­í•  (GPT ì£¼)\n",
        "# abstraction: â€œìƒ˜í”Œ í•˜ë‚˜â€ë¥¼ ê°€ì ¸ì˜¤ëŠ” í‘œì¤€ interface(__len__, __getitem__)ë¥¼ ì •ì˜\n",
        "# encapsulation: tokenizationÂ·label ë³€í™˜Â·augmentation ë“±ì„ on-the-flyë¡œ ì²˜ë¦¬\n",
        "train_dataset = EmotionDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = EmotionDataset(val_texts, val_labels, tokenizer)\n",
        "test_dataset = EmotionDataset(test_texts, test_labels, tokenizer)\n",
        "\n",
        "# DataLoaderì˜ ì—­í•  (GPT ì£¼)\n",
        "# batchÂ·shuffleÂ·parallel I/OÂ·pin-memory ë“±ì˜ running engine ê¸°ëŠ¥ ë‹´ë‹¹\n",
        "# GPU pipelineì„ ë³‘ë ¬í™”í•˜ì—¬ I/O bottleneck ìµœì†Œí™”\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "ZVsStWoNXgjv"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "L_HBI8I6cCVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ZARga2pdcIxl"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Hyperparams"
      ],
      "metadata": {
        "id": "RYAfdYCKShVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"UICHEOL-HWANG/kobert\"\n",
        "NUM_LABELS = 7\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 3e-5\n",
        "WARMUP_DECAY_RATE = 0.1 # í•™ìŠµë¥  ì¦ê°€ => ê°ì†Œ\n",
        "PATIENCE = 3            # Early stoppingì„ ìœ„í•œ patience ê°’"
      ],
      "metadata": {
        "id": "i4O9KvAhSg3w"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Training"
      ],
      "metadata": {
        "id": "72u3j150cVm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    id2label=ID_2_LABEL,\n",
        "    label2id=LABEL_2_ID,\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True  # classification head í¬ê¸°ê°€ ë‹¬ë¼ë„ ìë™ êµì²´\n",
        ")\n",
        "\n",
        "model.to(device)  # ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "num_training_steps = NUM_EPOCHS * len(train_loader)\n",
        "num_warmup_steps = int(WARMUP_DECAY_RATE * num_training_steps)\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "7C08c1_YcNz4"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training (fine-tuning)"
      ],
      "metadata": {
        "id": "25twEcpLeTW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "# !!! ì¤‘ìš” !!!\n",
        "#\n",
        "# ì´ ì½”ë“œëŠ” ëª¨ë¸ì˜ ê²€ì¦ ê³¼ì •ì—ì„œ early-stoppingì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "#\n",
        "# early-stopping ì—†ì´ í•™ìŠµí•˜ê³ ì í•œë‹¤ë©´, ì´ ì½”ë“œ ë¸”ë¡ì„ **ì‹¤í–‰í•˜ì§€ ë§ˆì‹œê³ ** ë°”ë¡œ ì•„ë˜ì— ìˆëŠ” ì½”ë“œ ë¸”ë¡ì„ ì‹¤í–‰í•˜ì‹­ì‹œì˜¤.\n",
        "#\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Early Stopping ë³€ìˆ˜\n",
        "best_val_f1 = 0\n",
        "patience_counter = 0\n",
        "\n",
        "# ì „ì²´ ë°ì´í„°ë¥¼ {NUM_EPOCHS}íšŒ ìˆœíšŒí•˜ë©° í•™ìŠµ\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    ### í•™ìŠµ ê³¼ì •(train)\n",
        "\n",
        "    # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0\n",
        "    train_labels = []\n",
        "    train_preds = []\n",
        "\n",
        "    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ í•™ìŠµ ìˆ˜í–‰\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} [Training]\"):\n",
        "\n",
        "        # 1. ì…ë ¥ì„ GPUì— ì „ë‹¬\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "            \"labels\": batch[\"labels\"].to(device)\n",
        "        }\n",
        "\n",
        "        # 2. gradient ì´ˆê¸°í™”\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 3. forward pass\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # 4. ì˜ˆì¸¡ê°’ ì§‘ê³„\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        # 5. ì†ì‹¤ ì§‘ê³„\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "        train_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        # 6. ëª¨ë¸ íŒŒë¼ë¯¸í„° ê°±ì‹ (backward pass; back propagation)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    ### í•™ìŠµ ë‹¨ê³„ì—ì„œì˜ ì†ì‹¤ ë° metric ê³„ì‚°\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_accuracy = accuracy_score(train_labels, train_preds)\n",
        "    train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} \"\n",
        "        f\"Training Loss: {avg_train_loss:.4f} | \"\n",
        "        f\"Training Accuracy: {train_accuracy:.4f} | \"\n",
        "        f\"Training Macro F1: {train_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "    ### ê²€ì¦ ê³¼ì •(validation)\n",
        "\n",
        "    # ëª¨ë¸ì„ ê²€ì¦/í‰ê°€/ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_labels = []\n",
        "    val_preds = []\n",
        "\n",
        "    # ê²€ì¦ ê³¼ì •ì—ì„œëŠ” gradient ì—°ì‚°ì„ ìƒëµí•˜ì—¬ ì—°ì‚°ëŸ‰ ë° ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì„\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê²€ì¦ ìˆ˜í–‰\n",
        "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1} [Validation]\"):\n",
        "\n",
        "            # 1. ì…ë ¥ì„ GPUì— ì „ë‹¬\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "                \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "                \"labels\": batch[\"labels\"].to(device)\n",
        "            }\n",
        "\n",
        "            # 2. forward pass\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            # 3. ì˜ˆì¸¡ê°’ ì§‘ê³„\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            # 4. ì†ì‹¤ ì§‘ê³„\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "            val_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    ### ê²€ì¦ ë‹¨ê³„ì—ì„œì˜ ì†ì‹¤ ë° metric ê³„ì‚°\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} \"\n",
        "        f\"Validation Loss: {avg_val_loss:.4f} | \"\n",
        "        f\"Validation Accuracy: {val_accuracy:.4f} | \"\n",
        "        f\"Validation Macro F1: {val_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "    ### Early Stopping ì—¬ë¶€ í™•ì¸\n",
        "    if val_f1 > best_val_f1:                # ê°€ì¥ ë†’ì€ ì •í™•ë„ë¥¼ ê¸°ë¡í•˜ë©´\n",
        "        best_val_f1 = val_f1                # ì •í™•ë„ ê¸°ì¤€ì„ ê°±ì‹ \n",
        "        patience_counter = 0                # patience ì´ˆê¸°í™”\n",
        "\n",
        "        # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì €ì¥\n",
        "\n",
        "        ## ê²½ë¡œ ì„¤ì •\n",
        "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "        save_path = os.path.join(DIRECTORY, \"sentiment\", f\"{MODEL_NAME.replace('/', '_')}_{timestamp}\")\n",
        "        model_path = os.path.join(save_path, \"model\")\n",
        "        tokenizer_path = os.path.join(save_path, \"tokenizer\")\n",
        "\n",
        "        ## ëª¨ë¸ ì €ì¥\n",
        "        model.save_pretrained(model_path)\n",
        "\n",
        "        ## í† í¬ë‚˜ì´ì € ì €ì¥ (KoBertTokenizerëŠ” save_pretrained()ë¥¼ ì§€ì›í•˜ì§€ ì•Šê¸°ì— ì§ì ‘ ì €ì¥)\n",
        "        ## ì‚¬ì‹¤ KoBertTokenizerë¥¼ ê·¸ëŒ€ë¡œ ì¨ë„ ë¨...\n",
        "\n",
        "        ### ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "        os.makedirs(tokenizer_path, exist_ok=True)\n",
        "\n",
        "        ### vocab.txt ì €ì¥\n",
        "        tokenizer.save_vocabulary(tokenizer_path)\n",
        "\n",
        "        ### config.json ì €ì¥\n",
        "        with open(os.path.join(tokenizer_path, \"tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            import json\n",
        "            json.dump({\n",
        "                \"do_lower_case\": False,\n",
        "                \"unk_token\": \"[UNK]\",\n",
        "                \"sep_token\": \"[SEP]\",\n",
        "                \"pad_token\": \"[PAD]\",\n",
        "                \"cls_token\": \"[CLS]\",\n",
        "                \"mask_token\": \"[MASK]\"\n",
        "            }, f, indent=4)\n",
        "    else:                                   # ê·¸ë ‡ì§€ ëª»í•˜ë©´\n",
        "        patience_counter += 1               # patience ê°’ì„ 1 ì¦ê°€\n",
        "        print(\n",
        "            f\"Validation accuracy did not improve. \"\n",
        "            f\"Patience counter: {patience_counter}/{PATIENCE}\"\n",
        "        )\n",
        "\n",
        "    if patience_counter >= PATIENCE:        # ì¼ì • epochì„ ìˆœíšŒí•  ë•Œê¹Œì§€ ì •í™•ë„ ê¸°ì¤€ì„ ê°±ì‹ í•˜ì§€ ëª»í•˜ë©´\n",
        "        print(\"Early stopping triggered.\")  #\n",
        "        break                               # í•™ìŠµ ì¢…ë£Œ"
      ],
      "metadata": {
        "id": "NiW_q-0_eJBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432ca8c0-09eb-46b5-d3ef-68e6212b42e2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [03:30<00:00,  5.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Training Loss: 1.0282 | Training Accuracy: 0.6165 | Training Macro F1: 0.6158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:22<00:00, 16.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Validation Loss: 0.9844 | Validation Accuracy: 0.6257 | Validation Macro F1: 0.6273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [03:29<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Training Loss: 1.0084 | Training Accuracy: 0.6198 | Training Macro F1: 0.6195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:22<00:00, 16.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Validation Loss: 1.0384 | Validation Accuracy: 0.6067 | Validation Macro F1: 0.6008\n",
            "Validation accuracy did not improve. Patience counter: 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [03:28<00:00,  5.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Training Loss: 0.8644 | Training Accuracy: 0.6777 | Training Macro F1: 0.6772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:22<00:00, 16.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Validation Loss: 1.1682 | Validation Accuracy: 0.5782 | Validation Macro F1: 0.5775\n",
            "Validation accuracy did not improve. Patience counter: 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [03:29<00:00,  5.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Training Loss: 0.6380 | Training Accuracy: 0.7637 | Training Macro F1: 0.7637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:22<00:00, 16.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Validation Loss: 1.2287 | Validation Accuracy: 0.5865 | Validation Macro F1: 0.5879\n",
            "Validation accuracy did not improve. Patience counter: 3/3\n",
            "Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "# !!! ì¤‘ìš” !!!\n",
        "#\n",
        "# ì´ ì½”ë“œëŠ” ëª¨ë¸ì˜ ê²€ì¦ ê³¼ì •ì—ì„œ early-stoppingì„ ìˆ˜í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "#\n",
        "# early-stopping ì—¬ë¶€ë¥¼ í™•ì¸í•˜ë©° í•™ìŠµí•˜ê³ ì í•œë‹¤ë©´, ì´ ì½”ë“œ ë¸”ë¡ì„ **ì‹¤í–‰í•˜ì§€ ë§ˆì‹œê³ ** ë°”ë¡œ ìœ„ì— ìˆëŠ” ì½”ë“œ ë¸”ë¡ì„ ì‹¤í–‰í•˜ì‹­ì‹œì˜¤.\n",
        "#\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# ì „ì²´ ë°ì´í„°ë¥¼ {NUM_EPOCHS}íšŒ ìˆœíšŒí•˜ë©° í•™ìŠµ\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    ### í•™ìŠµ ê³¼ì •(train)\n",
        "\n",
        "    # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0\n",
        "    train_labels = []\n",
        "    train_preds = []\n",
        "\n",
        "    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ í•™ìŠµ ìˆ˜í–‰\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} [Training]\"):\n",
        "\n",
        "        # 1. ì…ë ¥ì„ GPUì— ì „ë‹¬\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "            \"labels\": batch[\"labels\"].to(device)\n",
        "        }\n",
        "\n",
        "        # 2. gradient ì´ˆê¸°í™”\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 3. forward pass\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # 4. ì˜ˆì¸¡ê°’ ì§‘ê³„\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        # 5. ì†ì‹¤ ì§‘ê³„\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "        train_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        # 6. ëª¨ë¸ íŒŒë¼ë¯¸í„° ê°±ì‹ (backward pass; back propagation)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    ### í•™ìŠµ ë‹¨ê³„ì—ì„œì˜ ì†ì‹¤ ë° metric ê³„ì‚°\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_accuracy = accuracy_score(train_labels, train_preds)\n",
        "    train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} \"\n",
        "        f\"Training Loss: {avg_train_loss:.4f} | \"\n",
        "        f\"Training Accuracy: {train_accuracy:.4f} | \"\n",
        "        f\"Training Macro F1: {train_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "    ### ê²€ì¦ ê³¼ì •(validation)\n",
        "\n",
        "    # ëª¨ë¸ì„ ê²€ì¦/í‰ê°€/ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_labels = []\n",
        "    val_preds = []\n",
        "\n",
        "    # ê²€ì¦ ê³¼ì •ì—ì„œëŠ” gradient ì—°ì‚°ì„ ìƒëµí•˜ì—¬ ì—°ì‚°ëŸ‰ ë° ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì„\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê²€ì¦ ìˆ˜í–‰\n",
        "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1} [Validation]\"):\n",
        "\n",
        "            # 1. ì…ë ¥ì„ GPUì— ì „ë‹¬\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "                \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "                \"labels\": batch[\"labels\"].to(device)\n",
        "            }\n",
        "\n",
        "            # 2. forward pass\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            # 3. ì˜ˆì¸¡ê°’ ì§‘ê³„\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            # 4. ì†ì‹¤ ì§‘ê³„\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "            val_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    ### ê²€ì¦ ë‹¨ê³„ì—ì„œì˜ ì†ì‹¤ ë° metric ê³„ì‚°\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} \"\n",
        "        f\"Validation Loss: {avg_val_loss:.4f} | \"\n",
        "        f\"Validation Accuracy: {val_accuracy:.4f} | \"\n",
        "        f\"Validation Macro F1: {val_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì €ì¥\n",
        "\n",
        "## ê²½ë¡œ ì„¤ì •\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "save_path = os.path.join(DIRECTORY, \"sentiment\", f\"{MODEL_NAME.replace('/', '_')}_{timestamp}\")\n",
        "model_path = os.path.join(save_path, \"model\")\n",
        "tokenizer_path = os.path.join(save_path, \"tokenizer\")\n",
        "\n",
        "## ëª¨ë¸ ì €ì¥\n",
        "model.save_pretrained(model_path)\n",
        "\n",
        "## í† í¬ë‚˜ì´ì € ì €ì¥ (KoBertTokenizerëŠ” save_pretrained()ë¥¼ ì§€ì›í•˜ì§€ ì•Šê¸°ì— ì§ì ‘ ì €ì¥)\n",
        "## ì‚¬ì‹¤ KoBertTokenizerë¥¼ ê·¸ëŒ€ë¡œ ì¨ë„ ë¨...\n",
        "\n",
        "### ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "os.makedirs(tokenizer_path, exist_ok=True)\n",
        "\n",
        "### vocab.txt ì €ì¥\n",
        "tokenizer.save_vocabulary(tokenizer_path)\n",
        "\n",
        "### config.json ì €ì¥\n",
        "with open(os.path.join(tokenizer_path, \"tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    import json\n",
        "    json.dump({\n",
        "        \"do_lower_case\": False,\n",
        "        \"unk_token\": \"[UNK]\",\n",
        "        \"sep_token\": \"[SEP]\",\n",
        "        \"pad_token\": \"[PAD]\",\n",
        "        \"cls_token\": \"[CLS]\",\n",
        "        \"mask_token\": \"[MASK]\"\n",
        "    }, f, indent=4)"
      ],
      "metadata": {
        "id": "QaEgiZcrPhw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "x0NXa6Achqua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Pre-trained Model"
      ],
      "metadata": {
        "id": "dgqaF3oBH5dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê¸°í•™ìŠµ ëª¨ë¸ì˜ ê²½ë¡œ\n",
        "path = \"/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    os.path.join(path, \"model\")\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    os.path.join(path, \"model\"),\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6np5eb_WH5rA",
        "outputId": "dac9da99-3911-4653-c7dd-60b03017e9fd"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "GNvzvvCOH53T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # ëª¨ë¸ì„ ê²€ì¦/í‰ê°€/ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸\n",
        "test_loss = 0.0\n",
        "test_labels = []\n",
        "test_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"[Test]\"):\n",
        "\n",
        "        # ì…ë ¥ì„ GPUë¡œ ì „ë‹¬\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "            \"labels\": batch[\"labels\"].to(device)\n",
        "        }\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # ì˜ˆì¸¡ê°’ ì§‘ê³„\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        # ì†ì‹¤ ì§‘ê³„\n",
        "        loss  = outputs.loss\n",
        "        test_loss += loss.item()\n",
        "        test_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "        test_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "# metric ê³„ì‚°\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = accuracy_score(test_labels, test_preds)\n",
        "test_f1 = f1_score(test_labels, test_preds, average=\"macro\")\n",
        "\n",
        "print(f\"Test Loss: {avg_test_loss:.4f} | \"\n",
        "      f\"Test Accuracy: {test_accuracy:.4f} | \"\n",
        "      f\"Test Macro F1: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "zjcfk_q5hyNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6c6b92-bcbf-4933-c5eb-bbd2295d0721"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:23<00:00, 15.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.1020 | Test Accuracy: 0.6243 | Test Macro F1: 0.5806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Test"
      ],
      "metadata": {
        "id": "wYWhHQ2pKDvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label dictionary\n",
        "LABEL_2_ID = {\n",
        "    \"ê³µí¬\": 0,\n",
        "    \"ë†€ëŒ\": 1,\n",
        "    \"ë¶„ë…¸\": 2,\n",
        "    \"ìŠ¬í””\": 3,\n",
        "    \"ì¤‘ë¦½\": 4,\n",
        "    \"í–‰ë³µ\": 5,\n",
        "    \"í˜ì˜¤\": 6,\n",
        "}\n",
        "ID_2_LABEL = {value: key for key, value in LABEL_2_ID.items()}"
      ],
      "metadata": {
        "id": "-r5Zg3htj9Ok"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í…ìŠ¤íŠ¸ í´ë¦¬ë‹ í•¨ìˆ˜ ì •ì˜\n",
        "URL_PAT = re.compile(r'https?://\\S+')\n",
        "HTML_PAT = re.compile(r'<[^>]+>')\n",
        "REPEAT_PAT = re.compile(r'(.)\\1{2,}')                       # 3íšŒ ì´ìƒ ì—°ì†ëœ ê¸€ì(ã…‹ã…‹ã…‹, ã… ã… ã…  ë“±) â†’ 2íšŒë¡œ ì¶•ì•½\n",
        "SPEC_PAT = re.compile(r'[^ã„±-ã…ê°€-í£a-zA-Z0-9\\s\\.\\,\\!\\?]+') # í—ˆìš© ë¬¸ì: í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±, ì£¼ìš” punctuation\n",
        "MULTI_SP = re.compile(r'\\s+')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = html.unescape(text)                          # &quot; â†’ \"\n",
        "    text = URL_PAT.sub(' URL ', text)                   # URL í† í°í™”\n",
        "    text = HTML_PAT.sub(' ', text)                      # HTML tag ì œê±°\n",
        "    text = emoji.demojize(text, delimiters=(' ', ' '))  # ğŸ˜€ â†’ :grinning_face:\n",
        "    text = REPEAT_PAT.sub(r'\\1\\1', text)                # ã…‹ã…‹ã…‹ã…‹ â†’ ã…‹ã…‹\n",
        "    text = SPEC_PAT.sub(' ', text)                      # íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
        "    text = unicodedata.normalize('NFKC', text)          # Unicode ì •ê·œí™”\n",
        "    text = MULTI_SP.sub(' ', text).strip()              # ë‹¤ì¤‘ ê³µë°± ì •ê·œí™”\n",
        "    return text"
      ],
      "metadata": {
        "id": "oGs0jNsrAe0s"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ ì •ì˜ ë° ì´ˆê¸°í™”\n",
        "\n",
        "# ê¸°í•™ìŠµ ëª¨ë¸ì˜ ê²½ë¡œ\n",
        "path = \"/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    os.path.join(path, \"model\")\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    os.path.join(path, \"model\"),\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CXkesxFxhd-1",
        "outputId": "2fd1cff4-ce55-4954-e66f-8dc92a3e770a"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì…ë ¥ í…ìŠ¤íŠ¸\n",
        "text = [\n",
        "    \"Hello Mr. my yesterday\",\n",
        "    \"ì „í•´ì£¼ì§€ ì•Šì„ë˜\",\n",
        "    \"ê¿ˆì´ ì´ë£¨ì–´ì§€ëŠ” ê·¸ë•Œ ê¼­ ë‹¤ì‹œ ë§Œë‚˜ìê³ \",\n",
        "    \"ë¯¸ì¹˜ë„ë¡ ë‚´ë‹¬ë ¤ë„ ì•ì´ ë³´ì´ì§€ ì•Šì•„\",\n",
        "    \"ë©ê·¸ëŸ¬ë‹ˆ í™€ë¡œ ë‚¨ê²¨ì ¸ ê¸¸ ìœ„ì— í„¸ì©\",\n",
        "    \"ì£¼ì €ì•‰ì•„ ì• ì¨ ëˆˆë¬¼ì„ ì°¸ìœ¼ë ¤ í–ˆì–´\",\n",
        "    \"ì´ˆë¼í•œ ë‚´ê°€ ì‹«ì–´ì„œ...\",\n",
        "    \"Hello Mr. my yesterday\",\n",
        "    \"íƒ€ì„ë¨¸ì‹ ì„ íƒ€ê³ \",\n",
        "    \"ê¿ˆì„ ì«“ëŠ” ì–´ì œì˜ ë‚´ê²Œ ì „í•´ì•¼ ë  ì–˜ê¸°\",\n",
        "    \"ë‚´ ì „ë¶€ë¥¼ ê±¸ê³  ë§¹ì„¸í• ê²Œ ì‚¶ì´ ëë‚œë‹¤ í•´ë„\",\n",
        "    \"ê¿ˆì´ ì´ë¤„ì§ˆ ê·¸ë•Œ ë„ˆë¥¼ ë§ì´í•˜ëŸ¬ ê°€ê² ì–´\"\n",
        "]\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
        "preprocessed_text = [clean_text(t) for t in text]\n",
        "\n",
        "# í† í¬ë‚˜ì´ì € ì •ì˜\n",
        "MODEL_NAME = \"UICHEOL-HWANG/kobert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "# í…ìŠ¤íŠ¸ í† í°í™”\n",
        "tokenized_text = tokenizer(\n",
        "    preprocessed_text,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=128,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# ëª¨ë¸ì„ GPUë¡œ ì´ë™\n",
        "model.to(device)\n",
        "\n",
        "# ëª¨ë¸ì„ ê²€ì¦/í‰ê°€/ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜\n",
        "model.eval()\n",
        "\n",
        "# ì¶”ë¡ \n",
        "with torch.no_grad():\n",
        "\n",
        "    # ì…ë ¥ì„ GPUì— ì „ë‹¬\n",
        "    inputs = {\n",
        "        \"input_ids\": tokenized_text[\"input_ids\"].to(device),\n",
        "        \"attention_mask\": tokenized_text[\"attention_mask\"].to(device)\n",
        "    }\n",
        "\n",
        "    # ì¶”ë¡ \n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "for text, logit, pred in zip(text, logits, preds):\n",
        "    print(f\"ì…ë ¥ í…ìŠ¤íŠ¸: {text}\")\n",
        "    print(f\"ê°ì • ë²¡í„°: {[round(num.item(), 3) for num in logit.cpu().numpy()]}\")\n",
        "    print(f\"ì˜ˆì¸¡ëœ ê°ì •: {ID_2_LABEL[int(pred)]}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "b8JyVIp8KHbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f8b706-3535-4c1b-f588-067b14acea8e"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì…ë ¥ í…ìŠ¤íŠ¸: Hello Mr. my yesterday\n",
            "ê°ì • ë²¡í„°: [-0.581, 1.001, -1.79, 0.617, -0.046, 3.222, -2.119]\n",
            "ì˜ˆì¸¡ëœ ê°ì •: í–‰ë³µ\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: ì „í•´ì£¼ì§€ ì•Šì„ë˜\n",
            "ê°ì • ë²¡í„°: [1.274, -1.593, -0.015, 2.226, 1.147, -1.601, -1.015]\n",
            "ì˜ˆì¸¡ëœ ê°ì •: ìŠ¬í””\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: ê¿ˆì´ ì´ë£¨ì–´ì§€ëŠ” ê·¸ë•Œ ê¼­ ë‹¤ì‹œ ë§Œë‚˜ìê³ \n",
            "ê°ì • ë²¡í„°: [-1.022, -0.854, -1.464, 1.785, 0.725, 3.678, -1.773]\n",
            "ì˜ˆì¸¡ëœ ê°ì •: í–‰ë³µ\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: ë¯¸ì¹˜ë„ë¡ ë‚´ë‹¬ë ¤ë„ ì•ì´ ë³´ì´ì§€ ì•Šì•„\n",
            "ê°ì • ë²¡í„°: [1.675, -0.545, -0.837, 3.444, -0.884, -1.736, -1.656]\n",
            "ì˜ˆì¸¡ëœ ê°ì •: ìŠ¬í””\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: ë©ê·¸ëŸ¬ë‹ˆ í™€ë¡œ ë‚¨ê²¨ì ¸ ê¸¸ ìœ„ì— í„¸ì©\n",
            "ê°ì • ë²¡í„°: [0.095, -1.265, -0.093, 3.89, -0.412, -1.055, -0.777]\n",
            "ì˜ˆì¸¡ëœ ê°ì •: ìŠ¬í””\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: ì£¼ì €ì•‰ì•„ ì• ì¨ ëˆˆë¬¼ì„ ì°¸ìœ¼ë ¤ í–ˆì–´\n",
            "ê°ì • ë²¡í„°: [-0.512, -0.647, -0.543, 3.616, -0.274, 0.092, -1.47]\n",
            "ì˜ˆì¸¡ëœ ê°ì •: ìŠ¬í””\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: ì´ˆë¼í•œ ë‚´ê°€ ì‹«ì–´ì„œ...\n",
            "ê°ì • ë²¡í„°: [0.598, -1.356, -1.088, 4.576, -0.916, -0.524, -1.12]\n",
            "ì˜ˆì¸¡ëœ ê°ì •: ìŠ¬í””\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: Hello Mr. my yesterday\n",
            "ê°ì • ë²¡í„°: [-0.581, 1.001, -1.79, 0.617, -0.046, 3.222, -2.119]\n",
            "ì˜ˆì¸¡ëœ ê°ì •: í–‰ë³µ\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: íƒ€ì„ë¨¸ì‹ ì„ íƒ€ê³ \n",
            "ê°ì • ë²¡í„°: [-0.667, 0.171, -0.901, 1.154, 1.4, 0.957, -1.567]\n",
            "ì˜ˆì¸¡ëœ ê°ì •: ì¤‘ë¦½\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: ê¿ˆì„ ì«“ëŠ” ì–´ì œì˜ ë‚´ê²Œ ì „í•´ì•¼ ë  ì–˜ê¸°\n",
            "ê°ì • ë²¡í„°: [-0.807, -1.481, -0.991, 1.938, 1.437, 2.302, -1.152]\n",
            "ì˜ˆì¸¡ëœ ê°ì •: í–‰ë³µ\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: ë‚´ ì „ë¶€ë¥¼ ê±¸ê³  ë§¹ì„¸í• ê²Œ ì‚¶ì´ ëë‚œë‹¤ í•´ë„\n",
            "ê°ì • ë²¡í„°: [1.919, 0.03, -1.405, 2.159, 0.481, -0.906, -2.329]\n",
            "ì˜ˆì¸¡ëœ ê°ì •: ìŠ¬í””\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: ê¿ˆì´ ì´ë¤„ì§ˆ ê·¸ë•Œ ë„ˆë¥¼ ë§ì´í•˜ëŸ¬ ê°€ê² ì–´\n",
            "ê°ì • ë²¡í„°: [-0.607, -1.242, -1.439, 2.116, 1.561, 2.385, -1.567]\n",
            "ì˜ˆì¸¡ëœ ê°ì •: í–‰ë³µ\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline: Korean Hate Speech Detection"
      ],
      "metadata": {
        "id": "l24qaePWP0AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label dictionary\n",
        "LABEL_2_ID = {\n",
        "    0: 0,\n",
        "    1: 1,\n",
        "}\n",
        "ID_2_LABEL = {value: key for key, value in LABEL_2_ID.items()}"
      ],
      "metadata": {
        "id": "zTqeMHUsj5r6"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Datasets"
      ],
      "metadata": {
        "id": "En59iIE3k1Et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(os.path.join(DIRECTORY, 'train.tsv'), sep='\\t')\n",
        "df_validation = pd.read_csv(os.path.join(DIRECTORY, 'validation.tsv'), sep='\\t')\n",
        "df_test = pd.read_csv(os.path.join(DIRECTORY, 'test.tsv'), sep='\\t')"
      ],
      "metadata": {
        "id": "hV3vfdMkk3Pq"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "aWlg2fKTQtFF"
      },
      "outputs": [],
      "source": [
        "# dataset ë³‘í•©\n",
        "df = pd.concat([df_train, df_validation, df_test])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "id": "Q-Qdu7Q5mNE3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "collapsed": true,
        "outputId": "6030d4e8-794b-4929-87b3-023ee1ca3f2f"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                              text  label\n",
              "0                         ì–¸ë‹ˆ í™”ë©´ë©ˆì·„ì–´      0\n",
              "1                      ë””í”¼ì”¨ ë°•ì œìš”????      0\n",
              "2           ì² íŒ½ì”¨ê°€ ì €ë¥¼ ì¹´íŠ¸ë¡œ ì•”ì‚´í–ˆì–´ìœ ..(?)      0\n",
              "3                 íƒ€ìš°ëŸ¬ìŠ¤ ëª‡ì„¼ì¹˜ ì˜†ì— ë§ì•„ë†“ê³       0\n",
              "4                             íŒ€ë²„ê·¸ê°€      0\n",
              "...                            ...    ...\n",
              "499995                  ë„ˆë¬´ ì†ë³´ì´ì–ì•„ã…‹ã…‹      0\n",
              "499996                     ì•„íŒŒì„œ ì¡°í‡´í•¨      0\n",
              "499997  <@981538220909133885> ëŒì•„ì˜¤ì‡¼      0\n",
              "499998       ë„Œ ê³¨ì„ ë„£ê³  ë¯¸êµ­ í˜ëª…ì´ë¼ê³  ê³µí¬í–ˆì§€      0\n",
              "499999                     ì•„ì´ìœ  ì§­ì„?      0\n",
              "\n",
              "[5000000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff667791-2ec2-490b-a4a4-d674607c3214\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ì–¸ë‹ˆ í™”ë©´ë©ˆì·„ì–´</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ë””í”¼ì”¨ ë°•ì œìš”????</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ì² íŒ½ì”¨ê°€ ì €ë¥¼ ì¹´íŠ¸ë¡œ ì•”ì‚´í–ˆì–´ìœ ..(?)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>íƒ€ìš°ëŸ¬ìŠ¤ ëª‡ì„¼ì¹˜ ì˜†ì— ë§ì•„ë†“ê³ </td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>íŒ€ë²„ê·¸ê°€</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499995</th>\n",
              "      <td>ë„ˆë¬´ ì†ë³´ì´ì–ì•„ã…‹ã…‹</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499996</th>\n",
              "      <td>ì•„íŒŒì„œ ì¡°í‡´í•¨</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499997</th>\n",
              "      <td>&lt;@981538220909133885&gt; ëŒì•„ì˜¤ì‡¼</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499998</th>\n",
              "      <td>ë„Œ ê³¨ì„ ë„£ê³  ë¯¸êµ­ í˜ëª…ì´ë¼ê³  ê³µí¬í–ˆì§€</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499999</th>\n",
              "      <td>ì•„ì´ìœ  ì§­ì„?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff667791-2ec2-490b-a4a4-d674607c3214')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff667791-2ec2-490b-a4a4-d674607c3214 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff667791-2ec2-490b-a4a4-d674607c3214');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1aaa5bed-769b-4a1e-9e2e-e4cefd3939a8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1aaa5bed-769b-4a1e-9e2e-e4cefd3939a8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1aaa5bed-769b-4a1e-9e2e-e4cefd3939a8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a8888c95-713f-423c-9770-46bd2ccf800b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a8888c95-713f-423c-9770-46bd2ccf800b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "PBATQhQfbAXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checking missing data"
      ],
      "metadata": {
        "id": "LI-FtdNVmmaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = (df[\"text\"].fillna('').str.len() == 0) | (~df[\"label\"].isin(LABEL_2_ID))\n",
        "if mask.any(): print(f\"{mask.sum()} missing datas\")\n",
        "else: print(\"no missing data\")"
      ],
      "metadata": {
        "id": "WZrOY1ZF9us8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c046e80-e000-4813-d15d-30c1c605b7b2"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no missing data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset balancing"
      ],
      "metadata": {
        "id": "ZXxtSppwoMO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = (\n",
        "    df.groupby(\"label\")\n",
        "    .apply(lambda x: x.sample(n=df[\"label\"].value_counts().min(), random_state=42)) # down-sampling\n",
        "    .reset_index(drop=True)                                                         # multi-index ë°©ì§€\n",
        "    .sample(frac=1, random_state=42)\n",
        "    .reset_index(drop=True)\n",
        ")"
      ],
      "metadata": {
        "id": "cEju_cfZoOpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "039738eb-9359-4b34-82c3-6b2861200a3d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-92-1052033161.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda x: x.sample(n=df[\"label\"].value_counts().min(), random_state=42)) # down-sampling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### outliar processing"
      ],
      "metadata": {
        "id": "qe27Wm24n4vc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "collapsed": true,
        "id": "N9bXJNRpVL0U"
      },
      "outputs": [],
      "source": [
        "# Sentiment Analysisì˜ outliar processingê³¼ ë™ì¼í•œ í•„í„°ë§ í•¨ìˆ˜ë¥¼ ê°€ì§\n",
        "URL_PAT = re.compile(r'https?://\\S+')\n",
        "HTML_PAT = re.compile(r'<[^>]+>')\n",
        "REPEAT_PAT = re.compile(r'(.)\\1{2,}')                       # 3íšŒ ì´ìƒ ì—°ì†ëœ ê¸€ì(ã…‹ã…‹ã…‹, ã… ã… ã…  ë“±) â†’ 2íšŒë¡œ ì¶•ì•½\n",
        "SPEC_PAT = re.compile(r'[^ã„±-ã…ê°€-í£a-zA-Z0-9\\s\\.\\,\\!\\?]+') # í—ˆìš© ë¬¸ì: í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±, ì£¼ìš” punctuation\n",
        "MULTI_SP = re.compile(r'\\s+')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = html.unescape(text)                          # &quot; â†’ \"\n",
        "    text = URL_PAT.sub(' URL ', text)                   # URL í† í°í™”\n",
        "    text = HTML_PAT.sub(' ', text)                      # HTML tag ì œê±°\n",
        "    text = emoji.demojize(text, delimiters=(' ', ' '))  # ğŸ˜€ â†’ :grinning_face:\n",
        "    text = REPEAT_PAT.sub(r'\\1\\1', text)                # ã…‹ã…‹ã…‹ã…‹ â†’ ã…‹ã…‹\n",
        "    text = SPEC_PAT.sub(' ', text)                      # íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
        "    text = unicodedata.normalize('NFKC', text)          # Unicode ì •ê·œí™”\n",
        "    text = MULTI_SP.sub(' ', text).strip()              # ë‹¤ì¤‘ ê³µë°± ì •ê·œí™”\n",
        "    return text\n",
        "\n",
        "df[\"text\"] = df[\"text\"].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset slicing"
      ],
      "metadata": {
        "id": "zaw_WaJzo69L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# colabì˜ GPU ë©”ëª¨ë¦¬ ì œí•œìœ¼ë¡œ ì¸í•´ datasetì˜ ì¼ë¶€ë§Œ í•™ìŠµì— ì‚¬ìš©\n",
        "df = df.iloc[:30000]"
      ],
      "metadata": {
        "id": "NSIOT83F4K_C"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset split"
      ],
      "metadata": {
        "id": "AoqWYP3KpJ9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# featureì™€ target ë¶„ë¦¬\n",
        "texts = df[\"text\"].tolist()\n",
        "labels = df[\"label\"].tolist()\n",
        "\n",
        "# train/validation/test split\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    texts, labels,\n",
        "    test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_texts, train_labels,\n",
        "    test_size=0.25, random_state=42, stratify=train_labels\n",
        ")"
      ],
      "metadata": {
        "id": "yFf85HxOpKFK"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Tokenize"
      ],
      "metadata": {
        "id": "Nb_-t647Tafu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"UICHEOL-HWANG/kobert\"\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "WyB1NH8AozoF"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì´ì „ì— ì •ì˜í•œ í´ë˜ìŠ¤, ìƒëµ ê°€ëŠ¥\n",
        "class EmotionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    ë¬¸ì¥ê³¼ ë¼ë²¨ì„ ì½ì–´\n",
        "    Transformer í† í¬ë‚˜ì´ì €ë¡œ encoding\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.texts[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "train_dataset = EmotionDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = EmotionDataset(val_texts, val_labels, tokenizer)\n",
        "test_dataset = EmotionDataset(test_texts, test_labels, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "8f176pBbTann"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Vectorize - Sentiment Model Inference"
      ],
      "metadata": {
        "id": "dQu7wUGsq4Te"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "ycVGrD2o7fDH"
      },
      "outputs": [],
      "source": [
        "# GPU ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Pre-trained Model"
      ],
      "metadata": {
        "id": "MHCUWNp5VJls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê¸°í•™ìŠµ ëª¨ë¸ì˜ ê²½ë¡œ\n",
        "path = \"/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    os.path.join(path, \"model\")\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    os.path.join(path, \"model\"),\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P_5rL6znVH74",
        "outputId": "51d5fee6-0158-4777-c9b4-590b2f7d699a"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorize"
      ],
      "metadata": {
        "id": "EZP76Gq5cqrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_vectors = []\n",
        "val_vectors = []\n",
        "test_vectors = []\n",
        "\n",
        "train_labels = []\n",
        "val_labels = []\n",
        "test_labels = []\n",
        "\n",
        "# ëª¨ë¸ì„ ê²€ì¦/í‰ê°€/ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f\"[Inference - Training Data]\"):\n",
        "\n",
        "        # ì…ë ¥ì„ GPUì— ì „ë‹¬\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "            \"labels\": batch[\"labels\"].to(device)\n",
        "        }\n",
        "\n",
        "        # logit êµ¬í•˜ê¸°\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        train_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "        train_vectors.extend(logits.cpu().numpy())\n",
        "\n",
        "    for batch in tqdm(val_loader, desc=f\"[Inference - Validation Data]\"):\n",
        "\n",
        "        # ì…ë ¥ì„ GPUì— ì „ë‹¬\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "            \"labels\": batch[\"labels\"].to(device)\n",
        "        }\n",
        "\n",
        "        # logit êµ¬í•˜ê¸°\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "        val_vectors.extend(logits.cpu().numpy())\n",
        "\n",
        "    for batch in tqdm(test_loader, desc=f\"[Inference - Test Data]\"):\n",
        "\n",
        "        # ì…ë ¥ì„ GPUì— ì „ë‹¬\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "            \"labels\": batch[\"labels\"].to(device)\n",
        "        }\n",
        "\n",
        "        # logit êµ¬í•˜ê¸°\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        test_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "        test_vectors.extend(logits.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-TxlDOYaZC8",
        "outputId": "2f965edb-3efa-467d-a6ee-3ac93236f555"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Inference - Training Data]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [02:16<00:00,  8.24it/s]\n",
            "[Inference - Validation Data]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:45<00:00,  8.33it/s]\n",
            "[Inference - Test Data]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:45<00:00,  8.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryTargetDataset(Dataset):\n",
        "    \"\"\"\n",
        "    í•™ìŠµì— ë§ê²Œ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬\n",
        "    \"\"\"\n",
        "    def __init__(self, features, targets):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            'input': self.features[index],\n",
        "            'label': self.targets[index]\n",
        "        }\n",
        "\n",
        "train_dataset = BinaryTargetDataset(train_vectors, train_labels)\n",
        "val_dataset = BinaryTargetDataset(val_vectors, val_labels)\n",
        "test_dataset = BinaryTargetDataset(test_vectors, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "MMrJDqD016ko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e7cc96-05c9-468c-efc3-149e79389825"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-102-1308973523.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  self.features = torch.tensor(features, dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "nbBR-GH-8Ar9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Hyperparams"
      ],
      "metadata": {
        "id": "sIzmH6C38woo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SIZE = len(train_vectors[0])\n",
        "NUM_LABELS = 2\n",
        "HIDDEN_SIZE = 64\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 1e-3\n",
        "WARMUP_DECAY_RATE = 0.1 # í•™ìŠµë¥  ì¦ê°€ => ê°ì†Œ"
      ],
      "metadata": {
        "id": "vRQfdg9H8A0T"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Training"
      ],
      "metadata": {
        "id": "CRX8P3769NTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP ëª¨ë¸ ì •ì˜\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x  # ë¡œì§“ ì¶œë ¥\n",
        "\n",
        "input_size = INPUT_SIZE\n",
        "hidden_size = HIDDEN_SIZE\n",
        "num_classes = NUM_LABELS\n",
        "\n",
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "model = MLPClassifier(input_size, hidden_size, num_classes)\n",
        "\n",
        "# ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
        "model.to(device)\n",
        "\n",
        "# ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "num_training_steps = NUM_EPOCHS * len(train_loader)\n",
        "num_warmup_steps = int(WARMUP_DECAY_RATE * num_training_steps)\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "Qn6Ri7Pc9Nal"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "id": "S0hLk7ZL9FlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì „ì²´ ë°ì´í„°ë¥¼ {NUM_EPOCHS}íšŒ ìˆœíšŒí•˜ë©° í•™ìŠµ\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    ### í•™ìŠµ ê³¼ì •(train)\n",
        "\n",
        "    # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0\n",
        "    train_labels = []\n",
        "    train_preds = []\n",
        "\n",
        "    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ í•™ìŠµ ìˆ˜í–‰\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} [Training]\"):\n",
        "\n",
        "        # 1. ì…ë ¥ì„ GPUì— ì „ë‹¬\n",
        "        inputs = batch['input'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        # 2. gradient ì´ˆê¸°í™”\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 3. forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # 4. ì˜ˆì¸¡ê°’ ì§‘ê³„\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        # 5. ì†ì‹¤ ì§‘ê³„\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_loss += loss.item()\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        # 6. ëª¨ë¸ íŒŒë¼ë¯¸í„° ê°±ì‹ (backward pass; back propagation)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    ### í•™ìŠµ ë‹¨ê³„ì—ì„œì˜ ì†ì‹¤ ë° metric ê³„ì‚°\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_accuracy = accuracy_score(train_labels, train_preds)\n",
        "    train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} \"\n",
        "        f\"Training Loss: {avg_train_loss:.4f} | \"\n",
        "        f\"Training Accuracy: {train_accuracy:.4f} | \"\n",
        "        f\"Training Macro F1: {train_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "    ### ê²€ì¦ ê³¼ì •(validation)\n",
        "\n",
        "    # ëª¨ë¸ì„ ê²€ì¦/í‰ê°€/ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_labels = []\n",
        "    val_preds = []\n",
        "\n",
        "    with torch.no_grad():       # ê²€ì¦ ê³¼ì •ì—ì„œëŠ” gradient ì—°ì‚°ì„ ìƒëµ(torch.no_grad())í•˜ì—¬ ì—°ì‚°ëŸ‰ ë° ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì„\n",
        "\n",
        "        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê²€ì¦ ìˆ˜í–‰\n",
        "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1} [Validation]\"):\n",
        "\n",
        "            # 1. ì…ë ¥ì„ GPUì— ì „ë‹¬\n",
        "            inputs = batch['input'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # 2. forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # 3. ì˜ˆì¸¡ê°’ ì§‘ê³„\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            # 4. ì†ì‹¤ ì§‘ê³„\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    ### ê²€ì¦ ë‹¨ê³„ì—ì„œì˜ ì†ì‹¤ ë° metric ê³„ì‚°\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} \"\n",
        "        f\"Validation Loss: {avg_val_loss:.4f} | \"\n",
        "        f\"Validation Accuracy: {val_accuracy:.4f} | \"\n",
        "        f\"Validation Macro F1: {val_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì €ì¥\n",
        "\n",
        "## ê²½ë¡œ ì„¤ì •\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "save_path = os.path.join(DIRECTORY, \"hate_speech\", f\"my_model_{timestamp}\")\n",
        "model_path = os.path.join(save_path, \"model\")\n",
        "tokenizer_path = os.path.join(save_path, \"tokenizer\")\n",
        "\n",
        "## ëª¨ë¸ ì €ì¥\n",
        "\n",
        "### ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "### ëª¨ë¸ ì €ì¥\n",
        "torch.save(model.state_dict(), os.path.join(model_path, \"pytorch_model.bin\"))\n",
        "\n",
        "## í† í¬ë‚˜ì´ì € ì €ì¥ (KoBertTokenizerëŠ” save_pretrained()ë¥¼ ì§€ì›í•˜ì§€ ì•Šê¸°ì— ì§ì ‘ ì €ì¥)\n",
        "## ì‚¬ì‹¤ KoBertTokenizerë¥¼ ê·¸ëŒ€ë¡œ ì¨ë„ ë¨...\n",
        "\n",
        "### ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "os.makedirs(tokenizer_path, exist_ok=True)\n",
        "\n",
        "### vocab.txt ì €ì¥\n",
        "tokenizer.save_vocabulary(tokenizer_path)\n",
        "\n",
        "### config.json ì €ì¥\n",
        "with open(os.path.join(tokenizer_path, \"tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    import json\n",
        "    json.dump({\n",
        "        \"do_lower_case\": False,\n",
        "        \"unk_token\": \"[UNK]\",\n",
        "        \"sep_token\": \"[SEP]\",\n",
        "        \"pad_token\": \"[PAD]\",\n",
        "        \"cls_token\": \"[CLS]\",\n",
        "        \"mask_token\": \"[MASK]\"\n",
        "    }, f, indent=4)"
      ],
      "metadata": {
        "id": "Ig-YrC4H9kp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c793d45-9e54-41b3-c304-c5affc71e0c6",
        "collapsed": true
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:02<00:00, 442.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Training Loss: 0.5710 | Training Accuracy: 0.6943 | Training Macro F1: 0.6894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1023.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Validation Loss: 0.5166 | Validation Accuracy: 0.7467 | Validation Macro F1: 0.7461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:01<00:00, 575.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Training Loss: 0.5068 | Training Accuracy: 0.7487 | Training Macro F1: 0.7472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1793.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Validation Loss: 0.5051 | Validation Accuracy: 0.7543 | Validation Macro F1: 0.7528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:02<00:00, 525.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Training Loss: 0.5030 | Training Accuracy: 0.7479 | Training Macro F1: 0.7467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1285.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Validation Loss: 0.5052 | Validation Accuracy: 0.7542 | Validation Macro F1: 0.7534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:02<00:00, 521.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Training Loss: 0.5015 | Training Accuracy: 0.7502 | Training Macro F1: 0.7491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1776.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Validation Loss: 0.5016 | Validation Accuracy: 0.7533 | Validation Macro F1: 0.7516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:01<00:00, 632.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Training Loss: 0.5006 | Training Accuracy: 0.7520 | Training Macro F1: 0.7508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1759.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Validation Loss: 0.5002 | Validation Accuracy: 0.7553 | Validation Macro F1: 0.7542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:01<00:00, 626.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Training Loss: 0.4998 | Training Accuracy: 0.7528 | Training Macro F1: 0.7518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1768.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Validation Loss: 0.5047 | Validation Accuracy: 0.7570 | Validation Macro F1: 0.7568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:01<00:00, 627.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Training Loss: 0.4988 | Training Accuracy: 0.7521 | Training Macro F1: 0.7511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1788.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Validation Loss: 0.5008 | Validation Accuracy: 0.7548 | Validation Macro F1: 0.7534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:01<00:00, 620.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Training Loss: 0.4985 | Training Accuracy: 0.7524 | Training Macro F1: 0.7513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1714.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Validation Loss: 0.4992 | Validation Accuracy: 0.7558 | Validation Macro F1: 0.7550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:02<00:00, 513.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Training Loss: 0.4980 | Training Accuracy: 0.7509 | Training Macro F1: 0.7499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1333.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Validation Loss: 0.4983 | Validation Accuracy: 0.7552 | Validation Macro F1: 0.7536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:02<00:00, 527.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Training Loss: 0.4973 | Training Accuracy: 0.7511 | Training Macro F1: 0.7501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1661.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Validation Loss: 0.4988 | Validation Accuracy: 0.7557 | Validation Macro F1: 0.7548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:01<00:00, 637.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Training Loss: 0.4972 | Training Accuracy: 0.7529 | Training Macro F1: 0.7519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1658.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Validation Loss: 0.4975 | Validation Accuracy: 0.7585 | Validation Macro F1: 0.7574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:01<00:00, 622.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Training Loss: 0.4966 | Training Accuracy: 0.7538 | Training Macro F1: 0.7528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1660.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Validation Loss: 0.4984 | Validation Accuracy: 0.7565 | Validation Macro F1: 0.7557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:01<00:00, 612.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Training Loss: 0.4963 | Training Accuracy: 0.7551 | Training Macro F1: 0.7540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1555.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Validation Loss: 0.4980 | Validation Accuracy: 0.7562 | Validation Macro F1: 0.7555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:01<00:00, 624.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Training Loss: 0.4959 | Training Accuracy: 0.7531 | Training Macro F1: 0.7521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1650.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Validation Loss: 0.4995 | Validation Accuracy: 0.7568 | Validation Macro F1: 0.7556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:02<00:00, 542.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Training Loss: 0.4955 | Training Accuracy: 0.7543 | Training Macro F1: 0.7533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1340.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Validation Loss: 0.4990 | Validation Accuracy: 0.7568 | Validation Macro F1: 0.7563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:02<00:00, 526.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Training Loss: 0.4954 | Training Accuracy: 0.7550 | Training Macro F1: 0.7540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1759.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Validation Loss: 0.4976 | Validation Accuracy: 0.7565 | Validation Macro F1: 0.7555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:01<00:00, 614.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Training Loss: 0.4950 | Training Accuracy: 0.7534 | Training Macro F1: 0.7523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1746.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Validation Loss: 0.4974 | Validation Accuracy: 0.7573 | Validation Macro F1: 0.7566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:01<00:00, 601.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Training Loss: 0.4947 | Training Accuracy: 0.7540 | Training Macro F1: 0.7530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1739.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Validation Loss: 0.4971 | Validation Accuracy: 0.7580 | Validation Macro F1: 0.7572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:01<00:00, 628.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Training Loss: 0.4944 | Training Accuracy: 0.7547 | Training Macro F1: 0.7537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1742.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Validation Loss: 0.4971 | Validation Accuracy: 0.7573 | Validation Macro F1: 0.7566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1125/1125 [00:01<00:00, 622.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Training Loss: 0.4941 | Training Accuracy: 0.7544 | Training Macro F1: 0.7535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1766.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Validation Loss: 0.4972 | Validation Accuracy: 0.7570 | Validation Macro F1: 0.7562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "l975WUh8NxzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Pre-trained Model"
      ],
      "metadata": {
        "id": "OdyonAMl71Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ê¸°í•™ìŠµ ëª¨ë¸ì˜ ê²½ë¡œ\n",
        "# ëª¨ë¸ íŒŒì¼ì„ ì§€ì •\n",
        "path = \"/content/drive/MyDrive/DeepLearning/hate_speech/UICHEOL-HWANG_kobert_20250621-155603/model/pytorch_model.bin\"\n",
        "\n",
        "input_size = INPUT_SIZE\n",
        "hidden_size = HIDDEN_SIZE\n",
        "num_classes = NUM_LABELS\n",
        "\n",
        "model = MLPClassifier(input_size, hidden_size, num_classes)\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "WedTng2271hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5bc16e9-42bf-4271-b4d3-2db69eea4ecb"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(\n",
              "  (fc1): Linear(in_features=7, out_features=64, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "Zmcl9zOC71oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # ëª¨ë¸ì„ ê²€ì¦/í‰ê°€/ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸\n",
        "test_loss = 0.0\n",
        "test_labels = []\n",
        "test_preds = []\n",
        "\n",
        "with torch.no_grad():  # gradient ê³„ì‚° ë¹„í™œì„±í™”\n",
        "    for batch in tqdm(test_loader, desc=\"[Test]\"):\n",
        "\n",
        "        # ì…ë ¥ì„ GPUë¡œ ì „ë‹¬\n",
        "        inputs = batch['input'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # ì˜ˆì¸¡ê°’ ì§‘ê³„\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        # ì†ì‹¤ ì§‘ê³„\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "        test_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "# metric ê³„ì‚°\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = accuracy_score(test_labels, test_preds)\n",
        "test_f1 = f1_score(test_labels, test_preds, average=\"macro\")\n",
        "\n",
        "print(f\"Test Loss: {avg_test_loss:.4f} | \"\n",
        "      f\"Test Accuracy: {test_accuracy:.4f} | \"\n",
        "      f\"Test Macro F1: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "r1IIKR6A-I1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "983cb895-9bf6-46a4-ca2d-bc0d90629631"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<00:00, 1786.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.5084 | Test Accuracy: 0.7470 | Test Macro F1: 0.7455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Test"
      ],
      "metadata": {
        "id": "H7_VYO5IN0hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# í…ìŠ¤íŠ¸ í´ë¦¬ë‹ í•¨ìˆ˜ ì •ì˜\n",
        "URL_PAT = re.compile(r'https?://\\S+')\n",
        "HTML_PAT = re.compile(r'<[^>]+>')\n",
        "REPEAT_PAT = re.compile(r'(.)\\1{2,}')                       # 3íšŒ ì´ìƒ ì—°ì†ëœ ê¸€ì(ã…‹ã…‹ã…‹, ã… ã… ã…  ë“±) â†’ 2íšŒë¡œ ì¶•ì•½\n",
        "SPEC_PAT = re.compile(r'[^ã„±-ã…ê°€-í£a-zA-Z0-9\\s\\.\\,\\!\\?]+') # í—ˆìš© ë¬¸ì: í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±, ì£¼ìš” punctuation\n",
        "MULTI_SP = re.compile(r'\\s+')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = html.unescape(text)                          # &quot; â†’ \"\n",
        "    text = URL_PAT.sub(' URL ', text)                   # URL í† í°í™”\n",
        "    text = HTML_PAT.sub(' ', text)                      # HTML tag ì œê±°\n",
        "    text = emoji.demojize(text, delimiters=(' ', ' '))  # ğŸ˜€ â†’ :grinning_face:\n",
        "    text = REPEAT_PAT.sub(r'\\1\\1', text)                # ã…‹ã…‹ã…‹ã…‹ â†’ ã…‹ã…‹\n",
        "    text = SPEC_PAT.sub(' ', text)                      # íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
        "    text = unicodedata.normalize('NFKC', text)          # Unicode ì •ê·œí™”\n",
        "    text = MULTI_SP.sub(' ', text).strip()              # ë‹¤ì¤‘ ê³µë°± ì •ê·œí™”\n",
        "    return text"
      ],
      "metadata": {
        "id": "KfEbf_59BMA7"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP ëª¨ë¸ ì •ì˜\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x  # ë¡œì§“ ì¶œë ¥"
      ],
      "metadata": {
        "id": "xaiwvG2ZD25j"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Sentiment Analysis\n",
        "\n",
        "# ì…ë ¥ í…ìŠ¤íŠ¸\n",
        "text = [\n",
        "    \"ì¢‹ì€ ì•„ì¹¨ì´ì—ìš”!\",             # í˜ì˜¤ í‘œí˜„ ì•„ë‹˜\n",
        "    \"ê²€ë‘¥ì´ë“¤ì€ ë‹¤ ì£½ì—¬ë²„ë ¤ì•¼í•´\",   # í˜ì˜¤ í‘œí˜„\n",
        "    \"ë¶ˆ ì¢€ êº¼ì¤„ë˜?\",                # \"ì‹ \"\n",
        "    \"ì•¼ ì´ ë°˜ë€êµ°ë…¸ë¬´ ì‰í‚¤ì•¼\"       # í˜ì˜¤ í‘œí˜„\n",
        "]\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
        "preprocessed_text = [clean_text(t) for t in text]\n",
        "\n",
        "# í† í¬ë‚˜ì´ì € ì •ì˜\n",
        "MODEL_NAME = \"UICHEOL-HWANG/kobert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "# í…ìŠ¤íŠ¸ í† í°í™”\n",
        "tokenized_text = tokenizer(\n",
        "    preprocessed_text,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=128,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# ëª¨ë¸ ì •ì˜ ë° ì´ˆê¸°í™”\n",
        "path = \"/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    os.path.join(path, \"model\")\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    os.path.join(path, \"model\"),\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# ëª¨ë¸ì„ GPUì— ì „ë‹¬\n",
        "model.to(device)\n",
        "\n",
        "# ëª¨ë¸ì„ ê²€ì¦/í‰ê°€/ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜\n",
        "model.eval()\n",
        "\n",
        "# ì¶”ë¡ \n",
        "with torch.no_grad():\n",
        "\n",
        "    # ì…ë ¥ì„ GPUì— ì „ë‹¬\n",
        "    inputs = {\n",
        "        \"input_ids\": tokenized_text[\"input_ids\"].to(device),\n",
        "        \"attention_mask\": tokenized_text[\"attention_mask\"].to(device)\n",
        "    }\n",
        "\n",
        "    # ì¶”ë¡ \n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # ê°ì • ë²¡í„° ë°˜í™˜\n",
        "    logits = outputs.logits\n",
        "\n",
        "### Hate Speech Detection\n",
        "\n",
        "# ëª¨ë¸ ì •ì˜ ë° ì´ˆê¸°í™”\n",
        "INPUT_SIZE = logits.size(1)\n",
        "NUM_LABELS = 2\n",
        "HIDDEN_SIZE = 64\n",
        "\n",
        "input_size = INPUT_SIZE\n",
        "hidden_size = HIDDEN_SIZE\n",
        "num_classes = NUM_LABELS\n",
        "path = \"/content/drive/MyDrive/DeepLearning/hate_speech/UICHEOL-HWANG_kobert_20250621-155603/model/pytorch_model.bin\"\n",
        "\n",
        "model = MLPClassifier(input_size, hidden_size, num_classes)\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "# ëª¨ë¸ì„ GPUì— ì „ë‹¬\n",
        "model.to(device)\n",
        "\n",
        "# ëª¨ë¸ì„ ê²€ì¦/í‰ê°€/ì¶”ë¡  ëª¨ë“œë¡œ ì „í™˜\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    # ì…ë ¥ì„ GPUì— ì „ë‹¬\n",
        "    inputs = logits.to(device)\n",
        "\n",
        "    # ì¶”ë¡ \n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # ì˜ˆì¸¡ê°’ ì§‘ê³„\n",
        "    preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "for text, logit, output, label in zip(text, logits, outputs, preds):\n",
        "    print(f\"ì…ë ¥ í…ìŠ¤íŠ¸: {text}\")\n",
        "    print(f\"ê°ì • ë²¡í„°: {[round(num.item(), 3) for num in logit.cpu().numpy()]}\")\n",
        "    print(f\"í˜ì˜¤ í‘œí˜„ ì—¬ë¶€ ë²¡í„°: {[round(num.item(), 3) for num in output.cpu().numpy()]}\")\n",
        "    if label == 1: print(\"í˜ì˜¤ í‘œí˜„ì…ë‹ˆë‹¤.\")\n",
        "    else: print(\"í˜ì˜¤ í‘œí˜„ì´ ì•„ë‹™ë‹ˆë‹¤.\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "1-ODTw64N8bN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a69699-8402-403f-ecd8-58fd78fc8f98"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì…ë ¥ í…ìŠ¤íŠ¸: ì¢‹ì€ ì•„ì¹¨ì´ì—ìš”!\n",
            "ê°ì • ë²¡í„°: [-1.571, -0.331, -1.078, -0.146, 0.735, 4.941, -1.237]\n",
            "í˜ì˜¤ í‘œí˜„ ì—¬ë¶€ ë²¡í„°: [0.284, -0.859]\n",
            "í˜ì˜¤ í‘œí˜„ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: ê²€ë‘¥ì´ë“¤ì€ ë‹¤ ì£½ì—¬ë²„ë ¤ì•¼í•´\n",
            "ê°ì • ë²¡í„°: [-0.488, -0.683, 3.154, -0.448, 0.485, -1.693, -0.102]\n",
            "í˜ì˜¤ í‘œí˜„ ì—¬ë¶€ ë²¡í„°: [-0.918, 0.915]\n",
            "í˜ì˜¤ í‘œí˜„ì…ë‹ˆë‹¤.\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: ë¶ˆ ì¢€ êº¼ì¤„ë˜?\n",
            "ê°ì • ë²¡í„°: [0.83, 0.569, 0.865, -0.164, 1.361, -2.503, -0.959]\n",
            "í˜ì˜¤ í‘œí˜„ ì—¬ë¶€ ë²¡í„°: [-0.125, -0.199]\n",
            "í˜ì˜¤ í‘œí˜„ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
            "\n",
            "ì…ë ¥ í…ìŠ¤íŠ¸: ì•¼ ì´ ë°˜ë€êµ°ë…¸ë¬´ ì‰í‚¤ì•¼\n",
            "ê°ì • ë²¡í„°: [-1.191, 0.922, 1.423, -1.636, 1.541, -0.552, -0.069]\n",
            "í˜ì˜¤ í‘œí˜„ ì—¬ë¶€ ë²¡í„°: [-0.713, 0.967]\n",
            "í˜ì˜¤ í‘œí˜„ì…ë‹ˆë‹¤.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"$FINISH\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3oAaL1UCkeG",
        "outputId": "61c8cf67-e9e4-4b9c-c408-d0777af59752"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$FINISH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Legacy"
      ],
      "metadata": {
        "id": "gsqd0SClqEq2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAa_8322Tz8b",
        "outputId": "b6493d34-6f8c-40f3-fd56-21fbafc112a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository `monologg/kobert` contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/monologg/kobert.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n",
            "Input: ì˜¤ëŠ˜ ë„ˆë¬´ í–‰ë³µí•´!\n",
            "Predicted Label: ê¸°ì¨\n",
            "\n",
            "Input: ì§„ì§œ ì§œì¦ë‚˜ê³  í™”ë‚œë‹¤.\n",
            "Predicted Label: ë¶„ë…¸\n",
            "\n",
            "Input: ì´ê²Œ ë¬´ì„œì›Œì„œ ëª»í•˜ê² ì–´.\n",
            "Predicted Label: ê³µí¬\n",
            "\n",
            "Input: ë³„ ê°ì •ì´ ì—†ì–´ìš”.\n",
            "Predicted Label: ìŠ¬í””\n",
            "\n",
            "Input: ì¶©ê²©ì ì¸ ë‰´ìŠ¤ì˜€ì–´.\n",
            "Predicted Label: ë†€ëŒ\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# UICHEOL-HWANG/kobert sample code\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"UICHEOL-HWANG/kobert\")\n",
        "\n",
        "model.to(device)  # ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
        "model.eval()\n",
        "\n",
        "id2label = {\n",
        "    0: \"ê³µí¬\",   # Fear\n",
        "    1: \"ë†€ëŒ\",   # Surprise\n",
        "    2: \"ë¶„ë…¸\",   # Anger\n",
        "    3: \"ìŠ¬í””\",   # Sadness\n",
        "    4: \"ì¤‘ë¦½\",   # Neutral\n",
        "    5: \"í–‰ë³µ\",   # Joy\n",
        "    6: \"í˜ì˜¤\"    # Disgust\n",
        "}\n",
        "\n",
        "texts = [\n",
        "    \"ì˜¤ëŠ˜ ë„ˆë¬´ í–‰ë³µí•´!\",\n",
        "    \"ì§„ì§œ ì§œì¦ë‚˜ê³  í™”ë‚œë‹¤.\",\n",
        "    \"ì´ê²Œ ë¬´ì„œì›Œì„œ ëª»í•˜ê² ì–´.\",\n",
        "    \"ë³„ ê°ì •ì´ ì—†ì–´ìš”.\",\n",
        "    \"ì¶©ê²©ì ì¸ ë‰´ìŠ¤ì˜€ì–´.\"\n",
        "]\n",
        "\n",
        "\n",
        "def preprocess_and_tokenize(texts, tokenizer, max_length=128):\n",
        "    inputs = tokenizer(\n",
        "        texts,\n",
        "        padding=True,  # ë°°ì¹˜ í¬ê¸°ì— ë§ê²Œ íŒ¨ë”©\n",
        "        truncation=True,  # ìµœëŒ€ ê¸¸ì´ ì´ˆê³¼ ì‹œ ìë¦„\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\",  # PyTorch í…ì„œ ë°˜í™˜\n",
        "    )\n",
        "    return inputs\n",
        "\n",
        "inputs = preprocess_and_tokenize(texts, tokenizer)\n",
        "\n",
        "# ì…ë ¥ ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™\n",
        "inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "# 4. ì¸í¼ëŸ°ìŠ¤ ìˆ˜í–‰\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "\n",
        "# ì˜ˆì¸¡ ê²°ê³¼ ë§¤í•‘\n",
        "predicted_labels = [id2label[pred] for pred in predictions]\n",
        "\n",
        "# 6. ê²°ê³¼ ì¶œë ¥\n",
        "for text, label in zip(texts, predicted_labels):\n",
        "    print(f\"Input: {text}\")\n",
        "    print(f\"Predicted Label: {label}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "l24qaePWP0AM",
        "gsqd0SClqEq2"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}