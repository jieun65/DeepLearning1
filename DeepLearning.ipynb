{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Google Colab 환경에서 진행하였습니다.\n",
        "Korean Hate Speech Detection의 입력 텍스트에서 감정 벡터를 추출하기 위하여 Sentiment Analysis에서 학습(fine-tuning)한 모델을 활용하였습니다.  \n",
        "따라서 Sentiment Analysis를 진행한 이후에 Korean Hate Speech Detection을 진행하였습니다.  \n",
        "드라이브에 마운트하는 코드와 데이터셋을 가져오는 코드에서는 **데이터셋이 있는 디렉토리를 올바르게 지정**하여야 합니다.  \n",
        "또한 모델이 추론(inference)을 수행하는 코드에서는 **추론을 수행하고자 하는 모델 파일이 있는 디렉토리를 올바르게 지정**하여야 합니다.  \n",
        "Sentiment Analysis의 Model Training 코드에서는 early stopping 수행 여부에 따라 **두 블록의 학습 코드 중 하나만 실행**해야 합니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "kxf_XUrnBlwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment settings"
      ],
      "metadata": {
        "id": "zl0HOW1cLDzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### install modules"
      ],
      "metadata": {
        "id": "gIwJ776uxPaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 이모지 전처리\n",
        "!pip install --quiet emoji==2.11.1"
      ],
      "metadata": {
        "id": "cB9N7Xc-vb0V"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import modules"
      ],
      "metadata": {
        "id": "XbxHKYMJQv7K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "cvptqBeLMmXU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os                               # file system에 접근\n",
        "import re, html, unicodedata, emoji     # text preprocessing의 regular expression\n",
        "import gc                               # GPU memory cache 청소\n",
        "import time\n",
        "\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
        "from transformers.optimization import get_scheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
        "from tqdm import tqdm                   # model training/validation/test에서 학습 과정을 시각화\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### drive mount"
      ],
      "metadata": {
        "id": "dbGjp7UrRFvK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOvCBqjpPJjm",
        "outputId": "fb519075-ccb1-407c-9362-8269e1c08705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "kmN7KUvGMz65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "304dcc61-a816-4d1b-bbd7-62dc64c19b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DeepLearning/sentiment.csv\n",
            "/content/drive/MyDrive/DeepLearning/test.tsv\n",
            "/content/drive/MyDrive/DeepLearning/validation.tsv\n",
            "/content/drive/MyDrive/DeepLearning/train.tsv\n",
            "/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152/model/config.json\n",
            "/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152/model/model.safetensors\n",
            "/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152/tokenizer/tokenizer_78b3253a26.model\n",
            "/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152/tokenizer/tokenizer_config.json\n",
            "/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152/tokenizer/vocab.txt\n",
            "/content/drive/MyDrive/DeepLearning/hate_speech/UICHEOL-HWANG_kobert_20250621-155603/model/pytorch_model.bin\n",
            "/content/drive/MyDrive/DeepLearning/hate_speech/UICHEOL-HWANG_kobert_20250621-155603/tokenizer/tokenizer_78b3253a26.model\n",
            "/content/drive/MyDrive/DeepLearning/hate_speech/UICHEOL-HWANG_kobert_20250621-155603/tokenizer/vocab.txt\n",
            "/content/drive/MyDrive/DeepLearning/hate_speech/UICHEOL-HWANG_kobert_20250621-155603/tokenizer/tokenizer_config.json\n"
          ]
        }
      ],
      "source": [
        "# directory check\n",
        "DIRECTORY = \"/content/drive/MyDrive/DeepLearning/\"\n",
        "for dirname, _, filenames in os.walk(DIRECTORY):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cuda"
      ],
      "metadata": {
        "id": "sBUqApGJRaL_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "oRHvi6v0Ob9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4fb897-b79b-477f-eb01-0633c7dce555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# 런타임 - 런타임 유형 변경 - T4 GPU 선택 - 저장(저장 필수)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"현재 device: {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(f\"현재 device: {device}\")\n",
        "    print(\"GPU 안 쓰면 학습 못함(진짜임)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline: Sentiment Analysis"
      ],
      "metadata": {
        "id": "d7iiafktAc-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label dictionary\n",
        "LABEL_2_ID = {\n",
        "    \"공포\": 0,\n",
        "    \"놀람\": 1,\n",
        "    \"분노\": 2,\n",
        "    \"슬픔\": 3,\n",
        "    \"중립\": 4,\n",
        "    \"행복\": 5,\n",
        "    \"혐오\": 6,\n",
        "}\n",
        "ID_2_LABEL = {value: key for key, value in LABEL_2_ID.items()}"
      ],
      "metadata": {
        "id": "ZLk4dgXAPMSR"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "iEae5UWya5lQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(os.path.join(DIRECTORY, 'sentiment.csv'))"
      ],
      "metadata": {
        "id": "zOZCCrF-Nnb3"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "id": "vIXLnkkXNt2s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "39fa3f41-485d-4e8f-8a50-852f50bea5d3",
        "collapsed": true
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                Sentence Emotion\n",
              "0                               언니 동생으로 부르는게 맞는 일인가요..??      공포\n",
              "1                                           그냥 내 느낌일뿐겠지?      공포\n",
              "2                                         아직너무초기라서 그런거죠?      공포\n",
              "3                                          유치원버스 사고 낫다던데      공포\n",
              "4                                            근데 원래이런거맞나요      공포\n",
              "...                                                  ...     ...\n",
              "38589               솔직히 예보 제대로 못하는 데 세금이라도 아끼게 그냥 폐지해라..      혐오\n",
              "38590                                        재미가 없으니 망하지      혐오\n",
              "38591  공장 도시락 비우생적임 아르바이트했는데 화장실가성 손도 않씯고 재료 담고 바닥 떨어...      혐오\n",
              "38592               코딱지 만한 나라에서 지들끼리 피터지게 싸우는 센징 클래스 ㅉㅉㅉ      혐오\n",
              "38593               와이프도 그렇고 댓글 다 볼텐데 이휘재 좀 하차 하라고 전해주세요      혐오\n",
              "\n",
              "[38594 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-676cdc16-45f0-4932-92e8-d743f75208f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>언니 동생으로 부르는게 맞는 일인가요..??</td>\n",
              "      <td>공포</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>그냥 내 느낌일뿐겠지?</td>\n",
              "      <td>공포</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>아직너무초기라서 그런거죠?</td>\n",
              "      <td>공포</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>유치원버스 사고 낫다던데</td>\n",
              "      <td>공포</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>근데 원래이런거맞나요</td>\n",
              "      <td>공포</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38589</th>\n",
              "      <td>솔직히 예보 제대로 못하는 데 세금이라도 아끼게 그냥 폐지해라..</td>\n",
              "      <td>혐오</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38590</th>\n",
              "      <td>재미가 없으니 망하지</td>\n",
              "      <td>혐오</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38591</th>\n",
              "      <td>공장 도시락 비우생적임 아르바이트했는데 화장실가성 손도 않씯고 재료 담고 바닥 떨어...</td>\n",
              "      <td>혐오</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38592</th>\n",
              "      <td>코딱지 만한 나라에서 지들끼리 피터지게 싸우는 센징 클래스 ㅉㅉㅉ</td>\n",
              "      <td>혐오</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38593</th>\n",
              "      <td>와이프도 그렇고 댓글 다 볼텐데 이휘재 좀 하차 하라고 전해주세요</td>\n",
              "      <td>혐오</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38594 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-676cdc16-45f0-4932-92e8-d743f75208f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-676cdc16-45f0-4932-92e8-d743f75208f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-676cdc16-45f0-4932-92e8-d743f75208f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d6dc0e78-6adc-479d-9c7f-7b8363f9a1d8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6dc0e78-6adc-479d-9c7f-7b8363f9a1d8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d6dc0e78-6adc-479d-9c7f-7b8363f9a1d8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_042dbba5-c948-4910-8f83-0b4935a60e4c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_042dbba5-c948-4910-8f83-0b4935a60e4c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 38594,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38509,\n        \"samples\": [\n          \"\\uac00\\uc815\\uc6a9\\ub204\\uc9c4\\uc138\\ub85c \\ubb50\\ud574\\uccd0\\uba39\\uc744\\ub7ec\\uace0 \\uc804\\uae30\\ub8cc \\ube44\\uc2f8\\uac8c\\ubc1b\\uc544\\uba39\\uace0 \\ub204\\uc9c4\\uc138 \\ud3d0\\uc9c0\\ud558\\uba74 \\ub420\\uac83\\uc744 \\uc800\\ub807\\uac8c \\uc2f8\\uc6b0\\uace0\\uc788\\uace0\",\n          \" \\uc544\\ub2c8\\uba74 \\uc11c\\ub85c \\ub9de\\uc9c0 \\uc54a\\uc544\\uc11c \\uadf8\\ub7f0\\uac78\\uae4c\\uc694?\",\n          \" \\uba54\\ub974\\ub610- \\uac70\\ub9ac\\ub294\\ub370 \\uc5b4\\uca4c\\uba74 \\uc88b\\uc8e0\\ub3cc\\uc544\\ubc84\\ub9b4\\uac83 \\uac19\\uc74c0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"\\uacf5\\ud3ec\",\n          \"\\ub180\\ub78c\",\n          \"\\ud589\\ubcf5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "RT3tcXtGO0fo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checking missing data"
      ],
      "metadata": {
        "id": "kNP5tkdRR18A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking missing data\n",
        "mask = (df[\"Sentence\"].fillna('').str.len() == 0) | (~df[\"Emotion\"].isin(LABEL_2_ID))\n",
        "if mask.any(): print(f\"{mask.sum()} missing datas\")\n",
        "else: print(\"no missing data\")"
      ],
      "metadata": {
        "id": "S7CkfILGOyTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea2f9818-ea3c-4e09-e246-158072d2c7c4"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no missing data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### outliar processing"
      ],
      "metadata": {
        "id": "-jdd-XqQR8e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL_PAT = re.compile(r'https?://\\S+')\n",
        "HTML_PAT = re.compile(r'<[^>]+>')\n",
        "REPEAT_PAT = re.compile(r'(.)\\1{2,}')                       # 3회 이상 연속된 글자(ㅋㅋㅋ, ㅠㅠㅠ 등) → 2회로 축약\n",
        "SPEC_PAT = re.compile(r'[^ㄱ-ㅎ가-힣a-zA-Z0-9\\s\\.\\,\\!\\?]+') # 허용 문자: 한글, 영문, 숫자, 공백, 주요 punctuation\n",
        "MULTI_SP = re.compile(r'\\s+')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = html.unescape(text)                          # &quot; → \"\n",
        "    text = URL_PAT.sub(' URL ', text)                   # URL 토큰화\n",
        "    text = HTML_PAT.sub(' ', text)                      # HTML tag 제거\n",
        "    text = emoji.demojize(text, delimiters=(' ', ' '))  # 😀 → :grinning_face:\n",
        "    text = REPEAT_PAT.sub(r'\\1\\1', text)                # ㅋㅋㅋㅋ → ㅋㅋ\n",
        "    text = SPEC_PAT.sub(' ', text)                      # 특수문자 제거\n",
        "    text = unicodedata.normalize('NFKC', text)          # Unicode 정규화\n",
        "    text = MULTI_SP.sub(' ', text).strip()              # 다중 공백 정규화\n",
        "    return text\n",
        "\n",
        "df[\"Sentence\"] = df[\"Sentence\"].apply(clean_text)"
      ],
      "metadata": {
        "id": "VsvvuRwvPzgX"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset balancing"
      ],
      "metadata": {
        "id": "s-6AEU1FSp6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = (\n",
        "    df.groupby(\"Emotion\")\n",
        "    .apply(lambda x: x.sample(n=df[\"Emotion\"].value_counts().min(), random_state=42))   # down-sampling\n",
        "    .reset_index(drop=True)                                                             # multi-index 방지\n",
        "    .sample(frac=1, random_state=42)\n",
        "    .reset_index(drop=True)\n",
        ")"
      ],
      "metadata": {
        "id": "7qFKt6sKSqTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d2c8ef-450c-4b92-a9a2-dc20f6d619b3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-69-349119925.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda x: x.sample(n=df[\"Emotion\"].value_counts().min(), random_state=42))   # down-sampling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### target digitize"
      ],
      "metadata": {
        "id": "c0OP6H_dSKrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [\"공포\", \"놀람\", \"분노\", ...] => [0, 1, 2, ...]\n",
        "df[\"Emotion\"] = df[\"Emotion\"].replace(LABEL_2_ID)"
      ],
      "metadata": {
        "id": "D6zINkDQSKzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e030355-02fe-4c37-a2df-08f09817c585"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-70-3228976304.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"Emotion\"] = df[\"Emotion\"].replace(LABEL_2_ID)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset slicing"
      ],
      "metadata": {
        "id": "ql00GoPtVkX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# colab의 GPU 메모리/연산 할당량 제한으로 인해 dataset의 일부만 학습에 사용\n",
        "df = df.iloc[:30000]"
      ],
      "metadata": {
        "id": "DwikQ4TCVjs3"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "collapsed": true,
        "id": "nYspxI3Pln0m",
        "outputId": "e28cb808-def6-4996-affc-9571fc5cc897"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                             Sentence  Emotion\n",
              "0                    이건 잘하는것 같은데 말이다.        0\n",
              "1                     그치만 타이밍이 문제네요..        0\n",
              "2                                대박??        5\n",
              "3                  시급 1600원 로봇 시급이 헐?        1\n",
              "4                          오늘 지진 대박이다        1\n",
              "...                               ...      ...\n",
              "29995                  진짜 네이트온만해야해?ᄏᄏ        0\n",
              "29996                  뭘해도 집중이안돼..힘들어        0\n",
              "29997  올해 한국시리즈는 최순실이한테 묻혀서 조용히 끝났네..        6\n",
              "29998        덕분에 새댁이 헤매지 않을 수 있게 되었어요        5\n",
              "29999         알바하면서 취업 준비 잘 할 수 있을까요?        0\n",
              "\n",
              "[30000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ec2418d-73a0-47d2-bfd9-784eea3d9e49\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>이건 잘하는것 같은데 말이다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>그치만 타이밍이 문제네요..</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>대박??</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>시급 1600원 로봇 시급이 헐?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>오늘 지진 대박이다</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29995</th>\n",
              "      <td>진짜 네이트온만해야해?ᄏᄏ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29996</th>\n",
              "      <td>뭘해도 집중이안돼..힘들어</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29997</th>\n",
              "      <td>올해 한국시리즈는 최순실이한테 묻혀서 조용히 끝났네..</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29998</th>\n",
              "      <td>덕분에 새댁이 헤매지 않을 수 있게 되었어요</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29999</th>\n",
              "      <td>알바하면서 취업 준비 잘 할 수 있을까요?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ec2418d-73a0-47d2-bfd9-784eea3d9e49')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ec2418d-73a0-47d2-bfd9-784eea3d9e49 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ec2418d-73a0-47d2-bfd9-784eea3d9e49');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-03b4820b-05c8-4263-b6bf-264cb10c7f5a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03b4820b-05c8-4263-b6bf-264cb10c7f5a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-03b4820b-05c8-4263-b6bf-264cb10c7f5a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7698e826-3f6c-4ec4-b953-4d52845b0668\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7698e826-3f6c-4ec4-b953-4d52845b0668 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30000,\n  \"fields\": [\n    {\n      \"column\": \"Sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29902,\n        \"samples\": [\n          \"\\uc8fd\\uc744\\uac83 \\uac19\\ub2e4\",\n          \"\\uc11c\\uc7a5\\ud6c8 \\ub3c4\\ub300\\uccb4 \\uc774\\uac8c \\ubb34\\uc2a8 \\uc758\\ubbf8\\uac00 \\uc788\\uc2b5\\ub2c8\\uae4c\",\n          \"\\uc131\\uc870\\uae30\\ub294 \\uc65c \\ud754\\ub4e4\\uace0 \\ub09c\\ub9ac\\uc57c!!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Emotion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset split"
      ],
      "metadata": {
        "id": "mxwCMCu1WqZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature와 target 분리\n",
        "texts = df[\"Sentence\"].tolist()\n",
        "labels = df[\"Emotion\"].tolist()\n",
        "\n",
        "# train/validation/test split\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    texts, labels,\n",
        "    test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_texts, train_labels,\n",
        "    test_size=0.25, random_state=42, stratify=train_labels\n",
        ")"
      ],
      "metadata": {
        "id": "OQif8Yq4WplB"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Tokenize"
      ],
      "metadata": {
        "id": "RgDC4yOKXgcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"UICHEOL-HWANG/kobert\"\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "Fi7medmLw2rw"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Tokenize"
      ],
      "metadata": {
        "id": "1l2QlNbkw2z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    문장과 라벨을 읽어\n",
        "    Transformer 토크나이저로 encoding\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=64):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.texts[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "# Dataset의 역할 (GPT 주)\n",
        "# abstraction: “샘플 하나”를 가져오는 표준 interface(__len__, __getitem__)를 정의\n",
        "# encapsulation: tokenization·label 변환·augmentation 등을 on-the-fly로 처리\n",
        "train_dataset = EmotionDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = EmotionDataset(val_texts, val_labels, tokenizer)\n",
        "test_dataset = EmotionDataset(test_texts, test_labels, tokenizer)\n",
        "\n",
        "# DataLoader의 역할 (GPT 주)\n",
        "# batch·shuffle·parallel I/O·pin-memory 등의 running engine 기능 담당\n",
        "# GPU pipeline을 병렬화하여 I/O bottleneck 최소화\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "ZVsStWoNXgjv"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "L_HBI8I6cCVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 메모리 캐시 정리\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ZARga2pdcIxl"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Hyperparams"
      ],
      "metadata": {
        "id": "RYAfdYCKShVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"UICHEOL-HWANG/kobert\"\n",
        "NUM_LABELS = 7\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 3e-5\n",
        "WARMUP_DECAY_RATE = 0.1 # 학습률 증가 => 감소\n",
        "PATIENCE = 3            # Early stopping을 위한 patience 값"
      ],
      "metadata": {
        "id": "i4O9KvAhSg3w"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Training"
      ],
      "metadata": {
        "id": "72u3j150cVm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        "    id2label=ID_2_LABEL,\n",
        "    label2id=LABEL_2_ID,\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True  # classification head 크기가 달라도 자동 교체\n",
        ")\n",
        "\n",
        "model.to(device)  # 모델을 디바이스로 이동\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "num_training_steps = NUM_EPOCHS * len(train_loader)\n",
        "num_warmup_steps = int(WARMUP_DECAY_RATE * num_training_steps)\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "7C08c1_YcNz4"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training (fine-tuning)"
      ],
      "metadata": {
        "id": "25twEcpLeTW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "# !!! 중요 !!!\n",
        "#\n",
        "# 이 코드는 모델의 검증 과정에서 early-stopping을 수행합니다.\n",
        "#\n",
        "# early-stopping 없이 학습하고자 한다면, 이 코드 블록을 **실행하지 마시고** 바로 아래에 있는 코드 블록을 실행하십시오.\n",
        "#\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Early Stopping 변수\n",
        "best_val_f1 = 0\n",
        "patience_counter = 0\n",
        "\n",
        "# 전체 데이터를 {NUM_EPOCHS}회 순회하며 학습\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    ### 학습 과정(train)\n",
        "\n",
        "    # 모델을 학습 모드로 전환\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0\n",
        "    train_labels = []\n",
        "    train_preds = []\n",
        "\n",
        "    # 배치 단위로 학습 수행\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} [Training]\"):\n",
        "\n",
        "        # 1. 입력을 GPU에 전달\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "            \"labels\": batch[\"labels\"].to(device)\n",
        "        }\n",
        "\n",
        "        # 2. gradient 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 3. forward pass\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # 4. 예측값 집계\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        # 5. 손실 집계\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "        train_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        # 6. 모델 파라미터 갱신(backward pass; back propagation)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    ### 학습 단계에서의 손실 및 metric 계산\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_accuracy = accuracy_score(train_labels, train_preds)\n",
        "    train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} \"\n",
        "        f\"Training Loss: {avg_train_loss:.4f} | \"\n",
        "        f\"Training Accuracy: {train_accuracy:.4f} | \"\n",
        "        f\"Training Macro F1: {train_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "    ### 검증 과정(validation)\n",
        "\n",
        "    # 모델을 검증/평가/추론 모드로 전환\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_labels = []\n",
        "    val_preds = []\n",
        "\n",
        "    # 검증 과정에서는 gradient 연산을 생략하여 연산량 및 오버헤드를 줄임\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # 배치 단위로 검증 수행\n",
        "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1} [Validation]\"):\n",
        "\n",
        "            # 1. 입력을 GPU에 전달\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "                \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "                \"labels\": batch[\"labels\"].to(device)\n",
        "            }\n",
        "\n",
        "            # 2. forward pass\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            # 3. 예측값 집계\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            # 4. 손실 집계\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "            val_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    ### 검증 단계에서의 손실 및 metric 계산\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} \"\n",
        "        f\"Validation Loss: {avg_val_loss:.4f} | \"\n",
        "        f\"Validation Accuracy: {val_accuracy:.4f} | \"\n",
        "        f\"Validation Macro F1: {val_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "    ### Early Stopping 여부 확인\n",
        "    if val_f1 > best_val_f1:                # 가장 높은 정확도를 기록하면\n",
        "        best_val_f1 = val_f1                # 정확도 기준을 갱신\n",
        "        patience_counter = 0                # patience 초기화\n",
        "\n",
        "        # 모델 및 토크나이저 저장\n",
        "\n",
        "        ## 경로 설정\n",
        "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "        save_path = os.path.join(DIRECTORY, \"sentiment\", f\"{MODEL_NAME.replace('/', '_')}_{timestamp}\")\n",
        "        model_path = os.path.join(save_path, \"model\")\n",
        "        tokenizer_path = os.path.join(save_path, \"tokenizer\")\n",
        "\n",
        "        ## 모델 저장\n",
        "        model.save_pretrained(model_path)\n",
        "\n",
        "        ## 토크나이저 저장 (KoBertTokenizer는 save_pretrained()를 지원하지 않기에 직접 저장)\n",
        "        ## 사실 KoBertTokenizer를 그대로 써도 됨...\n",
        "\n",
        "        ### 디렉토리 생성\n",
        "        os.makedirs(tokenizer_path, exist_ok=True)\n",
        "\n",
        "        ### vocab.txt 저장\n",
        "        tokenizer.save_vocabulary(tokenizer_path)\n",
        "\n",
        "        ### config.json 저장\n",
        "        with open(os.path.join(tokenizer_path, \"tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            import json\n",
        "            json.dump({\n",
        "                \"do_lower_case\": False,\n",
        "                \"unk_token\": \"[UNK]\",\n",
        "                \"sep_token\": \"[SEP]\",\n",
        "                \"pad_token\": \"[PAD]\",\n",
        "                \"cls_token\": \"[CLS]\",\n",
        "                \"mask_token\": \"[MASK]\"\n",
        "            }, f, indent=4)\n",
        "    else:                                   # 그렇지 못하면\n",
        "        patience_counter += 1               # patience 값을 1 증가\n",
        "        print(\n",
        "            f\"Validation accuracy did not improve. \"\n",
        "            f\"Patience counter: {patience_counter}/{PATIENCE}\"\n",
        "        )\n",
        "\n",
        "    if patience_counter >= PATIENCE:        # 일정 epoch을 순회할 때까지 정확도 기준을 갱신하지 못하면\n",
        "        print(\"Early stopping triggered.\")  #\n",
        "        break                               # 학습 종료"
      ],
      "metadata": {
        "id": "NiW_q-0_eJBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432ca8c0-09eb-46b5-d3ef-68e6212b42e2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Training]: 100%|██████████| 1125/1125 [03:30<00:00,  5.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Training Loss: 1.0282 | Training Accuracy: 0.6165 | Training Macro F1: 0.6158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Validation]: 100%|██████████| 375/375 [00:22<00:00, 16.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Validation Loss: 0.9844 | Validation Accuracy: 0.6257 | Validation Macro F1: 0.6273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Training]: 100%|██████████| 1125/1125 [03:29<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Training Loss: 1.0084 | Training Accuracy: 0.6198 | Training Macro F1: 0.6195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Validation]: 100%|██████████| 375/375 [00:22<00:00, 16.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Validation Loss: 1.0384 | Validation Accuracy: 0.6067 | Validation Macro F1: 0.6008\n",
            "Validation accuracy did not improve. Patience counter: 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Training]: 100%|██████████| 1125/1125 [03:28<00:00,  5.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Training Loss: 0.8644 | Training Accuracy: 0.6777 | Training Macro F1: 0.6772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Validation]: 100%|██████████| 375/375 [00:22<00:00, 16.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Validation Loss: 1.1682 | Validation Accuracy: 0.5782 | Validation Macro F1: 0.5775\n",
            "Validation accuracy did not improve. Patience counter: 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Training]: 100%|██████████| 1125/1125 [03:29<00:00,  5.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Training Loss: 0.6380 | Training Accuracy: 0.7637 | Training Macro F1: 0.7637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Validation]: 100%|██████████| 375/375 [00:22<00:00, 16.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Validation Loss: 1.2287 | Validation Accuracy: 0.5865 | Validation Macro F1: 0.5879\n",
            "Validation accuracy did not improve. Patience counter: 3/3\n",
            "Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "# !!! 중요 !!!\n",
        "#\n",
        "# 이 코드는 모델의 검증 과정에서 early-stopping을 수행하지 않습니다.\n",
        "#\n",
        "# early-stopping 여부를 확인하며 학습하고자 한다면, 이 코드 블록을 **실행하지 마시고** 바로 위에 있는 코드 블록을 실행하십시오.\n",
        "#\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# 전체 데이터를 {NUM_EPOCHS}회 순회하며 학습\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    ### 학습 과정(train)\n",
        "\n",
        "    # 모델을 학습 모드로 전환\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0\n",
        "    train_labels = []\n",
        "    train_preds = []\n",
        "\n",
        "    # 배치 단위로 학습 수행\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} [Training]\"):\n",
        "\n",
        "        # 1. 입력을 GPU에 전달\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "            \"labels\": batch[\"labels\"].to(device)\n",
        "        }\n",
        "\n",
        "        # 2. gradient 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 3. forward pass\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # 4. 예측값 집계\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        # 5. 손실 집계\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "        train_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        # 6. 모델 파라미터 갱신(backward pass; back propagation)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    ### 학습 단계에서의 손실 및 metric 계산\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_accuracy = accuracy_score(train_labels, train_preds)\n",
        "    train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} \"\n",
        "        f\"Training Loss: {avg_train_loss:.4f} | \"\n",
        "        f\"Training Accuracy: {train_accuracy:.4f} | \"\n",
        "        f\"Training Macro F1: {train_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "    ### 검증 과정(validation)\n",
        "\n",
        "    # 모델을 검증/평가/추론 모드로 전환\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_labels = []\n",
        "    val_preds = []\n",
        "\n",
        "    # 검증 과정에서는 gradient 연산을 생략하여 연산량 및 오버헤드를 줄임\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # 배치 단위로 검증 수행\n",
        "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1} [Validation]\"):\n",
        "\n",
        "            # 1. 입력을 GPU에 전달\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "                \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "                \"labels\": batch[\"labels\"].to(device)\n",
        "            }\n",
        "\n",
        "            # 2. forward pass\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            # 3. 예측값 집계\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            # 4. 손실 집계\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "            val_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    ### 검증 단계에서의 손실 및 metric 계산\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} \"\n",
        "        f\"Validation Loss: {avg_val_loss:.4f} | \"\n",
        "        f\"Validation Accuracy: {val_accuracy:.4f} | \"\n",
        "        f\"Validation Macro F1: {val_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "# 모델 및 토크나이저 저장\n",
        "\n",
        "## 경로 설정\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "save_path = os.path.join(DIRECTORY, \"sentiment\", f\"{MODEL_NAME.replace('/', '_')}_{timestamp}\")\n",
        "model_path = os.path.join(save_path, \"model\")\n",
        "tokenizer_path = os.path.join(save_path, \"tokenizer\")\n",
        "\n",
        "## 모델 저장\n",
        "model.save_pretrained(model_path)\n",
        "\n",
        "## 토크나이저 저장 (KoBertTokenizer는 save_pretrained()를 지원하지 않기에 직접 저장)\n",
        "## 사실 KoBertTokenizer를 그대로 써도 됨...\n",
        "\n",
        "### 디렉토리 생성\n",
        "os.makedirs(tokenizer_path, exist_ok=True)\n",
        "\n",
        "### vocab.txt 저장\n",
        "tokenizer.save_vocabulary(tokenizer_path)\n",
        "\n",
        "### config.json 저장\n",
        "with open(os.path.join(tokenizer_path, \"tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    import json\n",
        "    json.dump({\n",
        "        \"do_lower_case\": False,\n",
        "        \"unk_token\": \"[UNK]\",\n",
        "        \"sep_token\": \"[SEP]\",\n",
        "        \"pad_token\": \"[PAD]\",\n",
        "        \"cls_token\": \"[CLS]\",\n",
        "        \"mask_token\": \"[MASK]\"\n",
        "    }, f, indent=4)"
      ],
      "metadata": {
        "id": "QaEgiZcrPhw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "x0NXa6Achqua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Pre-trained Model"
      ],
      "metadata": {
        "id": "dgqaF3oBH5dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기학습 모델의 경로\n",
        "path = \"/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    os.path.join(path, \"model\")\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    os.path.join(path, \"model\"),\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6np5eb_WH5rA",
        "outputId": "dac9da99-3911-4653-c7dd-60b03017e9fd"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "GNvzvvCOH53T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # 모델을 검증/평가/추론 모드로 전환\n",
        "\n",
        "# 테스트\n",
        "test_loss = 0.0\n",
        "test_labels = []\n",
        "test_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"[Test]\"):\n",
        "\n",
        "        # 입력을 GPU로 전달\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "            \"labels\": batch[\"labels\"].to(device)\n",
        "        }\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # 예측값 집계\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        # 손실 집계\n",
        "        loss  = outputs.loss\n",
        "        test_loss += loss.item()\n",
        "        test_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "        test_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "# metric 계산\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = accuracy_score(test_labels, test_preds)\n",
        "test_f1 = f1_score(test_labels, test_preds, average=\"macro\")\n",
        "\n",
        "print(f\"Test Loss: {avg_test_loss:.4f} | \"\n",
        "      f\"Test Accuracy: {test_accuracy:.4f} | \"\n",
        "      f\"Test Macro F1: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "zjcfk_q5hyNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c6c6b92-bcbf-4933-c5eb-bbd2295d0721"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test]: 100%|██████████| 375/375 [00:23<00:00, 15.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.1020 | Test Accuracy: 0.6243 | Test Macro F1: 0.5806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Test"
      ],
      "metadata": {
        "id": "wYWhHQ2pKDvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label dictionary\n",
        "LABEL_2_ID = {\n",
        "    \"공포\": 0,\n",
        "    \"놀람\": 1,\n",
        "    \"분노\": 2,\n",
        "    \"슬픔\": 3,\n",
        "    \"중립\": 4,\n",
        "    \"행복\": 5,\n",
        "    \"혐오\": 6,\n",
        "}\n",
        "ID_2_LABEL = {value: key for key, value in LABEL_2_ID.items()}"
      ],
      "metadata": {
        "id": "-r5Zg3htj9Ok"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 클리닝 함수 정의\n",
        "URL_PAT = re.compile(r'https?://\\S+')\n",
        "HTML_PAT = re.compile(r'<[^>]+>')\n",
        "REPEAT_PAT = re.compile(r'(.)\\1{2,}')                       # 3회 이상 연속된 글자(ㅋㅋㅋ, ㅠㅠㅠ 등) → 2회로 축약\n",
        "SPEC_PAT = re.compile(r'[^ㄱ-ㅎ가-힣a-zA-Z0-9\\s\\.\\,\\!\\?]+') # 허용 문자: 한글, 영문, 숫자, 공백, 주요 punctuation\n",
        "MULTI_SP = re.compile(r'\\s+')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = html.unescape(text)                          # &quot; → \"\n",
        "    text = URL_PAT.sub(' URL ', text)                   # URL 토큰화\n",
        "    text = HTML_PAT.sub(' ', text)                      # HTML tag 제거\n",
        "    text = emoji.demojize(text, delimiters=(' ', ' '))  # 😀 → :grinning_face:\n",
        "    text = REPEAT_PAT.sub(r'\\1\\1', text)                # ㅋㅋㅋㅋ → ㅋㅋ\n",
        "    text = SPEC_PAT.sub(' ', text)                      # 특수문자 제거\n",
        "    text = unicodedata.normalize('NFKC', text)          # Unicode 정규화\n",
        "    text = MULTI_SP.sub(' ', text).strip()              # 다중 공백 정규화\n",
        "    return text"
      ],
      "metadata": {
        "id": "oGs0jNsrAe0s"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의 및 초기화\n",
        "\n",
        "# 기학습 모델의 경로\n",
        "path = \"/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    os.path.join(path, \"model\")\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    os.path.join(path, \"model\"),\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CXkesxFxhd-1",
        "outputId": "2fd1cff4-ce55-4954-e66f-8dc92a3e770a"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 텍스트\n",
        "text = [\n",
        "    \"Hello Mr. my yesterday\",\n",
        "    \"전해주지 않을래\",\n",
        "    \"꿈이 이루어지는 그때 꼭 다시 만나자고\",\n",
        "    \"미치도록 내달려도 앞이 보이지 않아\",\n",
        "    \"덩그러니 홀로 남겨져 길 위에 털썩\",\n",
        "    \"주저앉아 애써 눈물을 참으려 했어\",\n",
        "    \"초라한 내가 싫어서...\",\n",
        "    \"Hello Mr. my yesterday\",\n",
        "    \"타임머신을 타고\",\n",
        "    \"꿈을 쫓는 어제의 내게 전해야 될 얘기\",\n",
        "    \"내 전부를 걸고 맹세할게 삶이 끝난다 해도\",\n",
        "    \"꿈이 이뤄질 그때 너를 맞이하러 가겠어\"\n",
        "]\n",
        "\n",
        "# 텍스트 전처리\n",
        "preprocessed_text = [clean_text(t) for t in text]\n",
        "\n",
        "# 토크나이저 정의\n",
        "MODEL_NAME = \"UICHEOL-HWANG/kobert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "# 텍스트 토큰화\n",
        "tokenized_text = tokenizer(\n",
        "    preprocessed_text,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=128,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# 모델을 GPU로 이동\n",
        "model.to(device)\n",
        "\n",
        "# 모델을 검증/평가/추론 모드로 전환\n",
        "model.eval()\n",
        "\n",
        "# 추론\n",
        "with torch.no_grad():\n",
        "\n",
        "    # 입력을 GPU에 전달\n",
        "    inputs = {\n",
        "        \"input_ids\": tokenized_text[\"input_ids\"].to(device),\n",
        "        \"attention_mask\": tokenized_text[\"attention_mask\"].to(device)\n",
        "    }\n",
        "\n",
        "    # 추론\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "for text, logit, pred in zip(text, logits, preds):\n",
        "    print(f\"입력 텍스트: {text}\")\n",
        "    print(f\"감정 벡터: {[round(num.item(), 3) for num in logit.cpu().numpy()]}\")\n",
        "    print(f\"예측된 감정: {ID_2_LABEL[int(pred)]}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "b8JyVIp8KHbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f8b706-3535-4c1b-f588-067b14acea8e"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 텍스트: Hello Mr. my yesterday\n",
            "감정 벡터: [-0.581, 1.001, -1.79, 0.617, -0.046, 3.222, -2.119]\n",
            "예측된 감정: 행복\n",
            "\n",
            "입력 텍스트: 전해주지 않을래\n",
            "감정 벡터: [1.274, -1.593, -0.015, 2.226, 1.147, -1.601, -1.015]\n",
            "예측된 감정: 슬픔\n",
            "\n",
            "입력 텍스트: 꿈이 이루어지는 그때 꼭 다시 만나자고\n",
            "감정 벡터: [-1.022, -0.854, -1.464, 1.785, 0.725, 3.678, -1.773]\n",
            "예측된 감정: 행복\n",
            "\n",
            "입력 텍스트: 미치도록 내달려도 앞이 보이지 않아\n",
            "감정 벡터: [1.675, -0.545, -0.837, 3.444, -0.884, -1.736, -1.656]\n",
            "예측된 감정: 슬픔\n",
            "\n",
            "입력 텍스트: 덩그러니 홀로 남겨져 길 위에 털썩\n",
            "감정 벡터: [0.095, -1.265, -0.093, 3.89, -0.412, -1.055, -0.777]\n",
            "예측된 감정: 슬픔\n",
            "\n",
            "입력 텍스트: 주저앉아 애써 눈물을 참으려 했어\n",
            "감정 벡터: [-0.512, -0.647, -0.543, 3.616, -0.274, 0.092, -1.47]\n",
            "예측된 감정: 슬픔\n",
            "\n",
            "입력 텍스트: 초라한 내가 싫어서...\n",
            "감정 벡터: [0.598, -1.356, -1.088, 4.576, -0.916, -0.524, -1.12]\n",
            "예측된 감정: 슬픔\n",
            "\n",
            "입력 텍스트: Hello Mr. my yesterday\n",
            "감정 벡터: [-0.581, 1.001, -1.79, 0.617, -0.046, 3.222, -2.119]\n",
            "예측된 감정: 행복\n",
            "\n",
            "입력 텍스트: 타임머신을 타고\n",
            "감정 벡터: [-0.667, 0.171, -0.901, 1.154, 1.4, 0.957, -1.567]\n",
            "예측된 감정: 중립\n",
            "\n",
            "입력 텍스트: 꿈을 쫓는 어제의 내게 전해야 될 얘기\n",
            "감정 벡터: [-0.807, -1.481, -0.991, 1.938, 1.437, 2.302, -1.152]\n",
            "예측된 감정: 행복\n",
            "\n",
            "입력 텍스트: 내 전부를 걸고 맹세할게 삶이 끝난다 해도\n",
            "감정 벡터: [1.919, 0.03, -1.405, 2.159, 0.481, -0.906, -2.329]\n",
            "예측된 감정: 슬픔\n",
            "\n",
            "입력 텍스트: 꿈이 이뤄질 그때 너를 맞이하러 가겠어\n",
            "감정 벡터: [-0.607, -1.242, -1.439, 2.116, 1.561, 2.385, -1.567]\n",
            "예측된 감정: 행복\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline: Korean Hate Speech Detection"
      ],
      "metadata": {
        "id": "l24qaePWP0AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label dictionary\n",
        "LABEL_2_ID = {\n",
        "    0: 0,\n",
        "    1: 1,\n",
        "}\n",
        "ID_2_LABEL = {value: key for key, value in LABEL_2_ID.items()}"
      ],
      "metadata": {
        "id": "zTqeMHUsj5r6"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Datasets"
      ],
      "metadata": {
        "id": "En59iIE3k1Et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(os.path.join(DIRECTORY, 'train.tsv'), sep='\\t')\n",
        "df_validation = pd.read_csv(os.path.join(DIRECTORY, 'validation.tsv'), sep='\\t')\n",
        "df_test = pd.read_csv(os.path.join(DIRECTORY, 'test.tsv'), sep='\\t')"
      ],
      "metadata": {
        "id": "hV3vfdMkk3Pq"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "aWlg2fKTQtFF"
      },
      "outputs": [],
      "source": [
        "# dataset 병합\n",
        "df = pd.concat([df_train, df_validation, df_test])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "id": "Q-Qdu7Q5mNE3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "collapsed": true,
        "outputId": "6030d4e8-794b-4929-87b3-023ee1ca3f2f"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                              text  label\n",
              "0                         언니 화면멈췄어      0\n",
              "1                      디피씨 박제요????      0\n",
              "2           철팽씨가 저를 카트로 암살했어유..(?)      0\n",
              "3                 타우러스 몇센치 옆에 맞아놓고      0\n",
              "4                             팀버그가      0\n",
              "...                            ...    ...\n",
              "499995                  너무 속보이잖아ㅋㅋ      0\n",
              "499996                     아파서 조퇴함      0\n",
              "499997  <@981538220909133885> 돌아오쇼      0\n",
              "499998       넌 골을 넣고 미국 혁명이라고 공포했지      0\n",
              "499999                     아이유 짭임?      0\n",
              "\n",
              "[5000000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff667791-2ec2-490b-a4a4-d674607c3214\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>언니 화면멈췄어</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>디피씨 박제요????</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>철팽씨가 저를 카트로 암살했어유..(?)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>타우러스 몇센치 옆에 맞아놓고</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>팀버그가</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499995</th>\n",
              "      <td>너무 속보이잖아ㅋㅋ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499996</th>\n",
              "      <td>아파서 조퇴함</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499997</th>\n",
              "      <td>&lt;@981538220909133885&gt; 돌아오쇼</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499998</th>\n",
              "      <td>넌 골을 넣고 미국 혁명이라고 공포했지</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499999</th>\n",
              "      <td>아이유 짭임?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff667791-2ec2-490b-a4a4-d674607c3214')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff667791-2ec2-490b-a4a4-d674607c3214 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff667791-2ec2-490b-a4a4-d674607c3214');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1aaa5bed-769b-4a1e-9e2e-e4cefd3939a8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1aaa5bed-769b-4a1e-9e2e-e4cefd3939a8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1aaa5bed-769b-4a1e-9e2e-e4cefd3939a8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a8888c95-713f-423c-9770-46bd2ccf800b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a8888c95-713f-423c-9770-46bd2ccf800b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "PBATQhQfbAXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checking missing data"
      ],
      "metadata": {
        "id": "LI-FtdNVmmaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = (df[\"text\"].fillna('').str.len() == 0) | (~df[\"label\"].isin(LABEL_2_ID))\n",
        "if mask.any(): print(f\"{mask.sum()} missing datas\")\n",
        "else: print(\"no missing data\")"
      ],
      "metadata": {
        "id": "WZrOY1ZF9us8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c046e80-e000-4813-d15d-30c1c605b7b2"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no missing data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset balancing"
      ],
      "metadata": {
        "id": "ZXxtSppwoMO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = (\n",
        "    df.groupby(\"label\")\n",
        "    .apply(lambda x: x.sample(n=df[\"label\"].value_counts().min(), random_state=42)) # down-sampling\n",
        "    .reset_index(drop=True)                                                         # multi-index 방지\n",
        "    .sample(frac=1, random_state=42)\n",
        "    .reset_index(drop=True)\n",
        ")"
      ],
      "metadata": {
        "id": "cEju_cfZoOpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "039738eb-9359-4b34-82c3-6b2861200a3d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-92-1052033161.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda x: x.sample(n=df[\"label\"].value_counts().min(), random_state=42)) # down-sampling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### outliar processing"
      ],
      "metadata": {
        "id": "qe27Wm24n4vc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "collapsed": true,
        "id": "N9bXJNRpVL0U"
      },
      "outputs": [],
      "source": [
        "# Sentiment Analysis의 outliar processing과 동일한 필터링 함수를 가짐\n",
        "URL_PAT = re.compile(r'https?://\\S+')\n",
        "HTML_PAT = re.compile(r'<[^>]+>')\n",
        "REPEAT_PAT = re.compile(r'(.)\\1{2,}')                       # 3회 이상 연속된 글자(ㅋㅋㅋ, ㅠㅠㅠ 등) → 2회로 축약\n",
        "SPEC_PAT = re.compile(r'[^ㄱ-ㅎ가-힣a-zA-Z0-9\\s\\.\\,\\!\\?]+') # 허용 문자: 한글, 영문, 숫자, 공백, 주요 punctuation\n",
        "MULTI_SP = re.compile(r'\\s+')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = html.unescape(text)                          # &quot; → \"\n",
        "    text = URL_PAT.sub(' URL ', text)                   # URL 토큰화\n",
        "    text = HTML_PAT.sub(' ', text)                      # HTML tag 제거\n",
        "    text = emoji.demojize(text, delimiters=(' ', ' '))  # 😀 → :grinning_face:\n",
        "    text = REPEAT_PAT.sub(r'\\1\\1', text)                # ㅋㅋㅋㅋ → ㅋㅋ\n",
        "    text = SPEC_PAT.sub(' ', text)                      # 특수문자 제거\n",
        "    text = unicodedata.normalize('NFKC', text)          # Unicode 정규화\n",
        "    text = MULTI_SP.sub(' ', text).strip()              # 다중 공백 정규화\n",
        "    return text\n",
        "\n",
        "df[\"text\"] = df[\"text\"].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset slicing"
      ],
      "metadata": {
        "id": "zaw_WaJzo69L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# colab의 GPU 메모리 제한으로 인해 dataset의 일부만 학습에 사용\n",
        "df = df.iloc[:30000]"
      ],
      "metadata": {
        "id": "NSIOT83F4K_C"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset split"
      ],
      "metadata": {
        "id": "AoqWYP3KpJ9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature와 target 분리\n",
        "texts = df[\"text\"].tolist()\n",
        "labels = df[\"label\"].tolist()\n",
        "\n",
        "# train/validation/test split\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    texts, labels,\n",
        "    test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_texts, train_labels,\n",
        "    test_size=0.25, random_state=42, stratify=train_labels\n",
        ")"
      ],
      "metadata": {
        "id": "yFf85HxOpKFK"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Tokenize"
      ],
      "metadata": {
        "id": "Nb_-t647Tafu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"UICHEOL-HWANG/kobert\"\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "WyB1NH8AozoF"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이전에 정의한 클래스, 생략 가능\n",
        "class EmotionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    문장과 라벨을 읽어\n",
        "    Transformer 토크나이저로 encoding\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.texts[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "train_dataset = EmotionDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = EmotionDataset(val_texts, val_labels, tokenizer)\n",
        "test_dataset = EmotionDataset(test_texts, test_labels, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "8f176pBbTann"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Vectorize - Sentiment Model Inference"
      ],
      "metadata": {
        "id": "dQu7wUGsq4Te"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "ycVGrD2o7fDH"
      },
      "outputs": [],
      "source": [
        "# GPU 메모리 캐시 정리\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Pre-trained Model"
      ],
      "metadata": {
        "id": "MHCUWNp5VJls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기학습 모델의 경로\n",
        "path = \"/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    os.path.join(path, \"model\")\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    os.path.join(path, \"model\"),\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P_5rL6znVH74",
        "outputId": "51d5fee6-0158-4777-c9b4-590b2f7d699a"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorize"
      ],
      "metadata": {
        "id": "EZP76Gq5cqrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_vectors = []\n",
        "val_vectors = []\n",
        "test_vectors = []\n",
        "\n",
        "train_labels = []\n",
        "val_labels = []\n",
        "test_labels = []\n",
        "\n",
        "# 모델을 검증/평가/추론 모드로 전환\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f\"[Inference - Training Data]\"):\n",
        "\n",
        "        # 입력을 GPU에 전달\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "            \"labels\": batch[\"labels\"].to(device)\n",
        "        }\n",
        "\n",
        "        # logit 구하기\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        train_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "        train_vectors.extend(logits.cpu().numpy())\n",
        "\n",
        "    for batch in tqdm(val_loader, desc=f\"[Inference - Validation Data]\"):\n",
        "\n",
        "        # 입력을 GPU에 전달\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "            \"labels\": batch[\"labels\"].to(device)\n",
        "        }\n",
        "\n",
        "        # logit 구하기\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "        val_vectors.extend(logits.cpu().numpy())\n",
        "\n",
        "    for batch in tqdm(test_loader, desc=f\"[Inference - Test Data]\"):\n",
        "\n",
        "        # 입력을 GPU에 전달\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
        "            \"labels\": batch[\"labels\"].to(device)\n",
        "        }\n",
        "\n",
        "        # logit 구하기\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        test_labels.extend(inputs[\"labels\"].cpu().numpy())\n",
        "        test_vectors.extend(logits.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-TxlDOYaZC8",
        "outputId": "2f965edb-3efa-467d-a6ee-3ac93236f555"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Inference - Training Data]: 100%|██████████| 1125/1125 [02:16<00:00,  8.24it/s]\n",
            "[Inference - Validation Data]: 100%|██████████| 375/375 [00:45<00:00,  8.33it/s]\n",
            "[Inference - Test Data]: 100%|██████████| 375/375 [00:45<00:00,  8.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryTargetDataset(Dataset):\n",
        "    \"\"\"\n",
        "    학습에 맞게 데이터를 전처리\n",
        "    \"\"\"\n",
        "    def __init__(self, features, targets):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            'input': self.features[index],\n",
        "            'label': self.targets[index]\n",
        "        }\n",
        "\n",
        "train_dataset = BinaryTargetDataset(train_vectors, train_labels)\n",
        "val_dataset = BinaryTargetDataset(val_vectors, val_labels)\n",
        "test_dataset = BinaryTargetDataset(test_vectors, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "MMrJDqD016ko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e7cc96-05c9-468c-efc3-149e79389825"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-102-1308973523.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  self.features = torch.tensor(features, dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "nbBR-GH-8Ar9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Hyperparams"
      ],
      "metadata": {
        "id": "sIzmH6C38woo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SIZE = len(train_vectors[0])\n",
        "NUM_LABELS = 2\n",
        "HIDDEN_SIZE = 64\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 1e-3\n",
        "WARMUP_DECAY_RATE = 0.1 # 학습률 증가 => 감소"
      ],
      "metadata": {
        "id": "vRQfdg9H8A0T"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Training"
      ],
      "metadata": {
        "id": "CRX8P3769NTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP 모델 정의\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x  # 로짓 출력\n",
        "\n",
        "input_size = INPUT_SIZE\n",
        "hidden_size = HIDDEN_SIZE\n",
        "num_classes = NUM_LABELS\n",
        "\n",
        "# 모델 초기화\n",
        "model = MLPClassifier(input_size, hidden_size, num_classes)\n",
        "\n",
        "# 모델을 디바이스로 이동\n",
        "model.to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "num_training_steps = NUM_EPOCHS * len(train_loader)\n",
        "num_warmup_steps = int(WARMUP_DECAY_RATE * num_training_steps)\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "Qn6Ri7Pc9Nal"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "id": "S0hLk7ZL9FlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 데이터를 {NUM_EPOCHS}회 순회하며 학습\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    ### 학습 과정(train)\n",
        "\n",
        "    # 모델을 학습 모드로 전환\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0\n",
        "    train_labels = []\n",
        "    train_preds = []\n",
        "\n",
        "    # 배치 단위로 학습 수행\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} [Training]\"):\n",
        "\n",
        "        # 1. 입력을 GPU에 전달\n",
        "        inputs = batch['input'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        # 2. gradient 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 3. forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # 4. 예측값 집계\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        # 5. 손실 집계\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_loss += loss.item()\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        # 6. 모델 파라미터 갱신(backward pass; back propagation)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    ### 학습 단계에서의 손실 및 metric 계산\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_accuracy = accuracy_score(train_labels, train_preds)\n",
        "    train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} \"\n",
        "        f\"Training Loss: {avg_train_loss:.4f} | \"\n",
        "        f\"Training Accuracy: {train_accuracy:.4f} | \"\n",
        "        f\"Training Macro F1: {train_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "    ### 검증 과정(validation)\n",
        "\n",
        "    # 모델을 검증/평가/추론 모드로 전환\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_labels = []\n",
        "    val_preds = []\n",
        "\n",
        "    with torch.no_grad():       # 검증 과정에서는 gradient 연산을 생략(torch.no_grad())하여 연산량 및 오버헤드를 줄임\n",
        "\n",
        "        # 배치 단위로 검증 수행\n",
        "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1} [Validation]\"):\n",
        "\n",
        "            # 1. 입력을 GPU에 전달\n",
        "            inputs = batch['input'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # 2. forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # 3. 예측값 집계\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            # 4. 손실 집계\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    ### 검증 단계에서의 손실 및 metric 계산\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1} \"\n",
        "        f\"Validation Loss: {avg_val_loss:.4f} | \"\n",
        "        f\"Validation Accuracy: {val_accuracy:.4f} | \"\n",
        "        f\"Validation Macro F1: {val_f1:.4f}\"\n",
        "    )\n",
        "\n",
        "# 모델 및 토크나이저 저장\n",
        "\n",
        "## 경로 설정\n",
        "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "save_path = os.path.join(DIRECTORY, \"hate_speech\", f\"my_model_{timestamp}\")\n",
        "model_path = os.path.join(save_path, \"model\")\n",
        "tokenizer_path = os.path.join(save_path, \"tokenizer\")\n",
        "\n",
        "## 모델 저장\n",
        "\n",
        "### 디렉토리 생성\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "### 모델 저장\n",
        "torch.save(model.state_dict(), os.path.join(model_path, \"pytorch_model.bin\"))\n",
        "\n",
        "## 토크나이저 저장 (KoBertTokenizer는 save_pretrained()를 지원하지 않기에 직접 저장)\n",
        "## 사실 KoBertTokenizer를 그대로 써도 됨...\n",
        "\n",
        "### 디렉토리 생성\n",
        "os.makedirs(tokenizer_path, exist_ok=True)\n",
        "\n",
        "### vocab.txt 저장\n",
        "tokenizer.save_vocabulary(tokenizer_path)\n",
        "\n",
        "### config.json 저장\n",
        "with open(os.path.join(tokenizer_path, \"tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    import json\n",
        "    json.dump({\n",
        "        \"do_lower_case\": False,\n",
        "        \"unk_token\": \"[UNK]\",\n",
        "        \"sep_token\": \"[SEP]\",\n",
        "        \"pad_token\": \"[PAD]\",\n",
        "        \"cls_token\": \"[CLS]\",\n",
        "        \"mask_token\": \"[MASK]\"\n",
        "    }, f, indent=4)"
      ],
      "metadata": {
        "id": "Ig-YrC4H9kp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c793d45-9e54-41b3-c304-c5affc71e0c6",
        "collapsed": true
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Training]: 100%|██████████| 1125/1125 [00:02<00:00, 442.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Training Loss: 0.5710 | Training Accuracy: 0.6943 | Training Macro F1: 0.6894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1023.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Validation Loss: 0.5166 | Validation Accuracy: 0.7467 | Validation Macro F1: 0.7461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Training]: 100%|██████████| 1125/1125 [00:01<00:00, 575.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Training Loss: 0.5068 | Training Accuracy: 0.7487 | Training Macro F1: 0.7472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1793.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Validation Loss: 0.5051 | Validation Accuracy: 0.7543 | Validation Macro F1: 0.7528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Training]: 100%|██████████| 1125/1125 [00:02<00:00, 525.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Training Loss: 0.5030 | Training Accuracy: 0.7479 | Training Macro F1: 0.7467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1285.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Validation Loss: 0.5052 | Validation Accuracy: 0.7542 | Validation Macro F1: 0.7534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Training]: 100%|██████████| 1125/1125 [00:02<00:00, 521.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Training Loss: 0.5015 | Training Accuracy: 0.7502 | Training Macro F1: 0.7491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1776.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Validation Loss: 0.5016 | Validation Accuracy: 0.7533 | Validation Macro F1: 0.7516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Training]: 100%|██████████| 1125/1125 [00:01<00:00, 632.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Training Loss: 0.5006 | Training Accuracy: 0.7520 | Training Macro F1: 0.7508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1759.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Validation Loss: 0.5002 | Validation Accuracy: 0.7553 | Validation Macro F1: 0.7542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 [Training]: 100%|██████████| 1125/1125 [00:01<00:00, 626.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Training Loss: 0.4998 | Training Accuracy: 0.7528 | Training Macro F1: 0.7518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1768.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Validation Loss: 0.5047 | Validation Accuracy: 0.7570 | Validation Macro F1: 0.7568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 [Training]: 100%|██████████| 1125/1125 [00:01<00:00, 627.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Training Loss: 0.4988 | Training Accuracy: 0.7521 | Training Macro F1: 0.7511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1788.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Validation Loss: 0.5008 | Validation Accuracy: 0.7548 | Validation Macro F1: 0.7534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 [Training]: 100%|██████████| 1125/1125 [00:01<00:00, 620.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Training Loss: 0.4985 | Training Accuracy: 0.7524 | Training Macro F1: 0.7513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1714.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Validation Loss: 0.4992 | Validation Accuracy: 0.7558 | Validation Macro F1: 0.7550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 [Training]: 100%|██████████| 1125/1125 [00:02<00:00, 513.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Training Loss: 0.4980 | Training Accuracy: 0.7509 | Training Macro F1: 0.7499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1333.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Validation Loss: 0.4983 | Validation Accuracy: 0.7552 | Validation Macro F1: 0.7536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Training]: 100%|██████████| 1125/1125 [00:02<00:00, 527.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Training Loss: 0.4973 | Training Accuracy: 0.7511 | Training Macro F1: 0.7501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1661.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Validation Loss: 0.4988 | Validation Accuracy: 0.7557 | Validation Macro F1: 0.7548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Training]: 100%|██████████| 1125/1125 [00:01<00:00, 637.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Training Loss: 0.4972 | Training Accuracy: 0.7529 | Training Macro F1: 0.7519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1658.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Validation Loss: 0.4975 | Validation Accuracy: 0.7585 | Validation Macro F1: 0.7574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 [Training]: 100%|██████████| 1125/1125 [00:01<00:00, 622.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Training Loss: 0.4966 | Training Accuracy: 0.7538 | Training Macro F1: 0.7528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1660.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Validation Loss: 0.4984 | Validation Accuracy: 0.7565 | Validation Macro F1: 0.7557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 [Training]: 100%|██████████| 1125/1125 [00:01<00:00, 612.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Training Loss: 0.4963 | Training Accuracy: 0.7551 | Training Macro F1: 0.7540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1555.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Validation Loss: 0.4980 | Validation Accuracy: 0.7562 | Validation Macro F1: 0.7555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 [Training]: 100%|██████████| 1125/1125 [00:01<00:00, 624.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Training Loss: 0.4959 | Training Accuracy: 0.7531 | Training Macro F1: 0.7521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1650.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Validation Loss: 0.4995 | Validation Accuracy: 0.7568 | Validation Macro F1: 0.7556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 [Training]: 100%|██████████| 1125/1125 [00:02<00:00, 542.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Training Loss: 0.4955 | Training Accuracy: 0.7543 | Training Macro F1: 0.7533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1340.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Validation Loss: 0.4990 | Validation Accuracy: 0.7568 | Validation Macro F1: 0.7563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 [Training]: 100%|██████████| 1125/1125 [00:02<00:00, 526.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Training Loss: 0.4954 | Training Accuracy: 0.7550 | Training Macro F1: 0.7540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1759.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Validation Loss: 0.4976 | Validation Accuracy: 0.7565 | Validation Macro F1: 0.7555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 [Training]: 100%|██████████| 1125/1125 [00:01<00:00, 614.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Training Loss: 0.4950 | Training Accuracy: 0.7534 | Training Macro F1: 0.7523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1746.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Validation Loss: 0.4974 | Validation Accuracy: 0.7573 | Validation Macro F1: 0.7566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 [Training]: 100%|██████████| 1125/1125 [00:01<00:00, 601.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Training Loss: 0.4947 | Training Accuracy: 0.7540 | Training Macro F1: 0.7530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1739.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Validation Loss: 0.4971 | Validation Accuracy: 0.7580 | Validation Macro F1: 0.7572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 [Training]: 100%|██████████| 1125/1125 [00:01<00:00, 628.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Training Loss: 0.4944 | Training Accuracy: 0.7547 | Training Macro F1: 0.7537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1742.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Validation Loss: 0.4971 | Validation Accuracy: 0.7573 | Validation Macro F1: 0.7566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 [Training]: 100%|██████████| 1125/1125 [00:01<00:00, 622.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Training Loss: 0.4941 | Training Accuracy: 0.7544 | Training Macro F1: 0.7535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 [Validation]: 100%|██████████| 375/375 [00:00<00:00, 1766.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Validation Loss: 0.4972 | Validation Accuracy: 0.7570 | Validation Macro F1: 0.7562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "l975WUh8NxzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Pre-trained Model"
      ],
      "metadata": {
        "id": "OdyonAMl71Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기학습 모델의 경로\n",
        "# 모델 파일을 지정\n",
        "path = \"/content/drive/MyDrive/DeepLearning/hate_speech/UICHEOL-HWANG_kobert_20250621-155603/model/pytorch_model.bin\"\n",
        "\n",
        "input_size = INPUT_SIZE\n",
        "hidden_size = HIDDEN_SIZE\n",
        "num_classes = NUM_LABELS\n",
        "\n",
        "model = MLPClassifier(input_size, hidden_size, num_classes)\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "WedTng2271hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5bc16e9-42bf-4271-b4d3-2db69eea4ecb"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(\n",
              "  (fc1): Linear(in_features=7, out_features=64, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "Zmcl9zOC71oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # 모델을 검증/평가/추론 모드로 전환\n",
        "\n",
        "# 테스트\n",
        "test_loss = 0.0\n",
        "test_labels = []\n",
        "test_preds = []\n",
        "\n",
        "with torch.no_grad():  # gradient 계산 비활성화\n",
        "    for batch in tqdm(test_loader, desc=\"[Test]\"):\n",
        "\n",
        "        # 입력을 GPU로 전달\n",
        "        inputs = batch['input'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # 예측값 집계\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        # 손실 집계\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "        test_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "# metric 계산\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = accuracy_score(test_labels, test_preds)\n",
        "test_f1 = f1_score(test_labels, test_preds, average=\"macro\")\n",
        "\n",
        "print(f\"Test Loss: {avg_test_loss:.4f} | \"\n",
        "      f\"Test Accuracy: {test_accuracy:.4f} | \"\n",
        "      f\"Test Macro F1: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "r1IIKR6A-I1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "983cb895-9bf6-46a4-ca2d-bc0d90629631"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Test]: 100%|██████████| 375/375 [00:00<00:00, 1786.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.5084 | Test Accuracy: 0.7470 | Test Macro F1: 0.7455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Test"
      ],
      "metadata": {
        "id": "H7_VYO5IN0hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 클리닝 함수 정의\n",
        "URL_PAT = re.compile(r'https?://\\S+')\n",
        "HTML_PAT = re.compile(r'<[^>]+>')\n",
        "REPEAT_PAT = re.compile(r'(.)\\1{2,}')                       # 3회 이상 연속된 글자(ㅋㅋㅋ, ㅠㅠㅠ 등) → 2회로 축약\n",
        "SPEC_PAT = re.compile(r'[^ㄱ-ㅎ가-힣a-zA-Z0-9\\s\\.\\,\\!\\?]+') # 허용 문자: 한글, 영문, 숫자, 공백, 주요 punctuation\n",
        "MULTI_SP = re.compile(r'\\s+')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = html.unescape(text)                          # &quot; → \"\n",
        "    text = URL_PAT.sub(' URL ', text)                   # URL 토큰화\n",
        "    text = HTML_PAT.sub(' ', text)                      # HTML tag 제거\n",
        "    text = emoji.demojize(text, delimiters=(' ', ' '))  # 😀 → :grinning_face:\n",
        "    text = REPEAT_PAT.sub(r'\\1\\1', text)                # ㅋㅋㅋㅋ → ㅋㅋ\n",
        "    text = SPEC_PAT.sub(' ', text)                      # 특수문자 제거\n",
        "    text = unicodedata.normalize('NFKC', text)          # Unicode 정규화\n",
        "    text = MULTI_SP.sub(' ', text).strip()              # 다중 공백 정규화\n",
        "    return text"
      ],
      "metadata": {
        "id": "KfEbf_59BMA7"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP 모델 정의\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(MLPClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x  # 로짓 출력"
      ],
      "metadata": {
        "id": "xaiwvG2ZD25j"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Sentiment Analysis\n",
        "\n",
        "# 입력 텍스트\n",
        "text = [\n",
        "    \"좋은 아침이에요!\",             # 혐오 표현 아님\n",
        "    \"검둥이들은 다 죽여버려야해\",   # 혐오 표현\n",
        "    \"불 좀 꺼줄래?\",                # \"신\"\n",
        "    \"야 이 반란군노무 쉐키야\"       # 혐오 표현\n",
        "]\n",
        "\n",
        "# 텍스트 전처리\n",
        "preprocessed_text = [clean_text(t) for t in text]\n",
        "\n",
        "# 토크나이저 정의\n",
        "MODEL_NAME = \"UICHEOL-HWANG/kobert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "# 텍스트 토큰화\n",
        "tokenized_text = tokenizer(\n",
        "    preprocessed_text,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=128,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# 모델 정의 및 초기화\n",
        "path = \"/content/drive/MyDrive/DeepLearning/sentiment/UICHEOL-HWANG_kobert_20250621-093152\"\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    os.path.join(path, \"model\")\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    os.path.join(path, \"model\"),\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# 모델을 GPU에 전달\n",
        "model.to(device)\n",
        "\n",
        "# 모델을 검증/평가/추론 모드로 전환\n",
        "model.eval()\n",
        "\n",
        "# 추론\n",
        "with torch.no_grad():\n",
        "\n",
        "    # 입력을 GPU에 전달\n",
        "    inputs = {\n",
        "        \"input_ids\": tokenized_text[\"input_ids\"].to(device),\n",
        "        \"attention_mask\": tokenized_text[\"attention_mask\"].to(device)\n",
        "    }\n",
        "\n",
        "    # 추론\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # 감정 벡터 반환\n",
        "    logits = outputs.logits\n",
        "\n",
        "### Hate Speech Detection\n",
        "\n",
        "# 모델 정의 및 초기화\n",
        "INPUT_SIZE = logits.size(1)\n",
        "NUM_LABELS = 2\n",
        "HIDDEN_SIZE = 64\n",
        "\n",
        "input_size = INPUT_SIZE\n",
        "hidden_size = HIDDEN_SIZE\n",
        "num_classes = NUM_LABELS\n",
        "path = \"/content/drive/MyDrive/DeepLearning/hate_speech/UICHEOL-HWANG_kobert_20250621-155603/model/pytorch_model.bin\"\n",
        "\n",
        "model = MLPClassifier(input_size, hidden_size, num_classes)\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "# 모델을 GPU에 전달\n",
        "model.to(device)\n",
        "\n",
        "# 모델을 검증/평가/추론 모드로 전환\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    # 입력을 GPU에 전달\n",
        "    inputs = logits.to(device)\n",
        "\n",
        "    # 추론\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # 예측값 집계\n",
        "    preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "for text, logit, output, label in zip(text, logits, outputs, preds):\n",
        "    print(f\"입력 텍스트: {text}\")\n",
        "    print(f\"감정 벡터: {[round(num.item(), 3) for num in logit.cpu().numpy()]}\")\n",
        "    print(f\"혐오 표현 여부 벡터: {[round(num.item(), 3) for num in output.cpu().numpy()]}\")\n",
        "    if label == 1: print(\"혐오 표현입니다.\")\n",
        "    else: print(\"혐오 표현이 아닙니다.\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "1-ODTw64N8bN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a69699-8402-403f-ecd8-58fd78fc8f98"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 텍스트: 좋은 아침이에요!\n",
            "감정 벡터: [-1.571, -0.331, -1.078, -0.146, 0.735, 4.941, -1.237]\n",
            "혐오 표현 여부 벡터: [0.284, -0.859]\n",
            "혐오 표현이 아닙니다.\n",
            "\n",
            "입력 텍스트: 검둥이들은 다 죽여버려야해\n",
            "감정 벡터: [-0.488, -0.683, 3.154, -0.448, 0.485, -1.693, -0.102]\n",
            "혐오 표현 여부 벡터: [-0.918, 0.915]\n",
            "혐오 표현입니다.\n",
            "\n",
            "입력 텍스트: 불 좀 꺼줄래?\n",
            "감정 벡터: [0.83, 0.569, 0.865, -0.164, 1.361, -2.503, -0.959]\n",
            "혐오 표현 여부 벡터: [-0.125, -0.199]\n",
            "혐오 표현이 아닙니다.\n",
            "\n",
            "입력 텍스트: 야 이 반란군노무 쉐키야\n",
            "감정 벡터: [-1.191, 0.922, 1.423, -1.636, 1.541, -0.552, -0.069]\n",
            "혐오 표현 여부 벡터: [-0.713, 0.967]\n",
            "혐오 표현입니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"$FINISH\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3oAaL1UCkeG",
        "outputId": "61c8cf67-e9e4-4b9c-c408-d0777af59752"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$FINISH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Legacy"
      ],
      "metadata": {
        "id": "gsqd0SClqEq2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAa_8322Tz8b",
        "outputId": "b6493d34-6f8c-40f3-fd56-21fbafc112a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository `monologg/kobert` contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/monologg/kobert.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n",
            "Input: 오늘 너무 행복해!\n",
            "Predicted Label: 기쁨\n",
            "\n",
            "Input: 진짜 짜증나고 화난다.\n",
            "Predicted Label: 분노\n",
            "\n",
            "Input: 이게 무서워서 못하겠어.\n",
            "Predicted Label: 공포\n",
            "\n",
            "Input: 별 감정이 없어요.\n",
            "Predicted Label: 슬픔\n",
            "\n",
            "Input: 충격적인 뉴스였어.\n",
            "Predicted Label: 놀람\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# UICHEOL-HWANG/kobert sample code\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"UICHEOL-HWANG/kobert\")\n",
        "\n",
        "model.to(device)  # 모델을 디바이스로 이동\n",
        "model.eval()\n",
        "\n",
        "id2label = {\n",
        "    0: \"공포\",   # Fear\n",
        "    1: \"놀람\",   # Surprise\n",
        "    2: \"분노\",   # Anger\n",
        "    3: \"슬픔\",   # Sadness\n",
        "    4: \"중립\",   # Neutral\n",
        "    5: \"행복\",   # Joy\n",
        "    6: \"혐오\"    # Disgust\n",
        "}\n",
        "\n",
        "texts = [\n",
        "    \"오늘 너무 행복해!\",\n",
        "    \"진짜 짜증나고 화난다.\",\n",
        "    \"이게 무서워서 못하겠어.\",\n",
        "    \"별 감정이 없어요.\",\n",
        "    \"충격적인 뉴스였어.\"\n",
        "]\n",
        "\n",
        "\n",
        "def preprocess_and_tokenize(texts, tokenizer, max_length=128):\n",
        "    inputs = tokenizer(\n",
        "        texts,\n",
        "        padding=True,  # 배치 크기에 맞게 패딩\n",
        "        truncation=True,  # 최대 길이 초과 시 자름\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\",  # PyTorch 텐서 반환\n",
        "    )\n",
        "    return inputs\n",
        "\n",
        "inputs = preprocess_and_tokenize(texts, tokenizer)\n",
        "\n",
        "# 입력 데이터를 GPU로 이동\n",
        "inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "# 4. 인퍼런스 수행\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "\n",
        "# 예측 결과 매핑\n",
        "predicted_labels = [id2label[pred] for pred in predictions]\n",
        "\n",
        "# 6. 결과 출력\n",
        "for text, label in zip(texts, predicted_labels):\n",
        "    print(f\"Input: {text}\")\n",
        "    print(f\"Predicted Label: {label}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "l24qaePWP0AM",
        "gsqd0SClqEq2"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}